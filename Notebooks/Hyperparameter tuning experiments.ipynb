{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hyperparameter tuning experiments.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B1dqJeyb0ZCT","executionInfo":{"status":"ok","timestamp":1661594464280,"user_tz":-330,"elapsed":63500,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"a37e2cc8-f81e-4ef0-ed02-839f35c96712"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd '/content/drive/MyDrive/HEXR/Code'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJVuMfQomncI","executionInfo":{"status":"ok","timestamp":1661594645005,"user_tz":-330,"elapsed":749,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"0562316b-9b99-4e0e-82ab-4f7c9103d418"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/HEXR/Code\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"KBlrg5a96HlP","executionInfo":{"status":"ok","timestamp":1661594853603,"user_tz":-330,"elapsed":870,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}}},"outputs":[],"source":["import os\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd \n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.metrics import f1_score\n","\n","import supervised_models\n","import vime_self\n","import hexr_self\n","import utils\n","from supervised_models import logit, mlp\n","from utils import mask_generator, pretext_generator\n","from hexr_self import hexr_self\n","from vime_self import vime_self\n","from utils import perf_metric\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend\n","\n","#to load VIME original\n","\n","# from supervised_models import logit, mlp\n","# from vime_utils import mask_generator, pretext_generator\n","# from vime_self import vime_self\n","# from vime_utils import perf_metric"]},{"cell_type":"code","source":["os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"NrfysFLqn8yx","executionInfo":{"status":"ok","timestamp":1661594682705,"user_tz":-330,"elapsed":1552,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"0134057e-d4e3-4079-9d55-eedf076c24d7"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/HEXR/Code'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# Wheelchair data - class distro"],"metadata":{"id":"lsSIeZWm_4Zv"}},{"cell_type":"markdown","source":[],"metadata":{"id":"LM1ivhe2_2_5"}},{"cell_type":"code","source":["df = pd.read_excel(\"/content/drive/MyDrive/HEXR/Data/wheelchair.xlsx\")\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"EVgRQXldnjlS","executionInfo":{"status":"ok","timestamp":1659765786735,"user_tz":-330,"elapsed":18382,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"1bf8ecd0-094e-4c28-897c-8b3751125a0c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   acc_x_mean  acc_x_var  acc_y_mean  acc_y_var  acc_z_mean  acc_z_var  \\\n","0   -1.603980  -0.311325   -0.526657  -0.549885   -1.325651  -0.507062   \n","1   -0.889841  -0.290249   -0.927707  -0.416062   -0.796440  -0.473546   \n","2   -0.303827  -0.409482   -0.456042  -0.446343   -0.901742  -0.446502   \n","3    0.505161  -0.374137   -1.586482   0.146147   -1.282596  -0.495242   \n","4    2.277629  -0.159041   -1.923802  -0.311471   -0.936299  -0.486042   \n","\n","   acc_sum_mean  acc_abssum_mean  acc_sum_var  acc_abssum_var  ...  \\\n","0     -0.990690        -0.463685     0.736400        0.390874  ...   \n","1     -0.903325        -0.279788     0.733535        0.242131  ...   \n","2     -0.388539        -0.453204     0.277714        0.425273  ...   \n","3     -0.753759         0.034292     0.566740       -0.179302  ...   \n","4     -0.205633         0.280182     0.274213       -0.416002  ...   \n","\n","   gyr_y_mean  gyr_y_var  gyr_z_mean  gyr_z_var  gyr_sum_mean  \\\n","0   -0.793769  -0.616974   -0.325648  -0.383848     -0.375689   \n","1   -0.183748  -0.608310    0.145033  -0.254733      0.118083   \n","2   -0.088225  -0.530472   -0.251902  -0.347630     -0.267182   \n","3   -0.857720  -0.586661    0.269013   4.241005      0.211447   \n","4   -2.899875  -0.604365    4.072822   3.231337      3.867647   \n","\n","   gyr_abssum_mean  gyr_sum_var  gyr_abssum_var  gyr_maxabssum  class  \n","0        -0.751992    -0.313164       -0.308224      -0.535785    6.0  \n","1        -0.365378    -0.246513       -0.258558      -0.179973    6.0  \n","2        -0.597825    -0.311489       -0.306792      -0.468677    6.0  \n","3         1.073201    -0.202394        0.646930       1.338340    6.0  \n","4         3.842431     5.447309        5.358663       4.215949    6.0  \n","\n","[5 rows x 23 columns]"],"text/html":["\n","  <div id=\"df-52e7305b-ceea-4786-ac64-cb7e86efd353\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>acc_x_mean</th>\n","      <th>acc_x_var</th>\n","      <th>acc_y_mean</th>\n","      <th>acc_y_var</th>\n","      <th>acc_z_mean</th>\n","      <th>acc_z_var</th>\n","      <th>acc_sum_mean</th>\n","      <th>acc_abssum_mean</th>\n","      <th>acc_sum_var</th>\n","      <th>acc_abssum_var</th>\n","      <th>...</th>\n","      <th>gyr_y_mean</th>\n","      <th>gyr_y_var</th>\n","      <th>gyr_z_mean</th>\n","      <th>gyr_z_var</th>\n","      <th>gyr_sum_mean</th>\n","      <th>gyr_abssum_mean</th>\n","      <th>gyr_sum_var</th>\n","      <th>gyr_abssum_var</th>\n","      <th>gyr_maxabssum</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.603980</td>\n","      <td>-0.311325</td>\n","      <td>-0.526657</td>\n","      <td>-0.549885</td>\n","      <td>-1.325651</td>\n","      <td>-0.507062</td>\n","      <td>-0.990690</td>\n","      <td>-0.463685</td>\n","      <td>0.736400</td>\n","      <td>0.390874</td>\n","      <td>...</td>\n","      <td>-0.793769</td>\n","      <td>-0.616974</td>\n","      <td>-0.325648</td>\n","      <td>-0.383848</td>\n","      <td>-0.375689</td>\n","      <td>-0.751992</td>\n","      <td>-0.313164</td>\n","      <td>-0.308224</td>\n","      <td>-0.535785</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.889841</td>\n","      <td>-0.290249</td>\n","      <td>-0.927707</td>\n","      <td>-0.416062</td>\n","      <td>-0.796440</td>\n","      <td>-0.473546</td>\n","      <td>-0.903325</td>\n","      <td>-0.279788</td>\n","      <td>0.733535</td>\n","      <td>0.242131</td>\n","      <td>...</td>\n","      <td>-0.183748</td>\n","      <td>-0.608310</td>\n","      <td>0.145033</td>\n","      <td>-0.254733</td>\n","      <td>0.118083</td>\n","      <td>-0.365378</td>\n","      <td>-0.246513</td>\n","      <td>-0.258558</td>\n","      <td>-0.179973</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.303827</td>\n","      <td>-0.409482</td>\n","      <td>-0.456042</td>\n","      <td>-0.446343</td>\n","      <td>-0.901742</td>\n","      <td>-0.446502</td>\n","      <td>-0.388539</td>\n","      <td>-0.453204</td>\n","      <td>0.277714</td>\n","      <td>0.425273</td>\n","      <td>...</td>\n","      <td>-0.088225</td>\n","      <td>-0.530472</td>\n","      <td>-0.251902</td>\n","      <td>-0.347630</td>\n","      <td>-0.267182</td>\n","      <td>-0.597825</td>\n","      <td>-0.311489</td>\n","      <td>-0.306792</td>\n","      <td>-0.468677</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.505161</td>\n","      <td>-0.374137</td>\n","      <td>-1.586482</td>\n","      <td>0.146147</td>\n","      <td>-1.282596</td>\n","      <td>-0.495242</td>\n","      <td>-0.753759</td>\n","      <td>0.034292</td>\n","      <td>0.566740</td>\n","      <td>-0.179302</td>\n","      <td>...</td>\n","      <td>-0.857720</td>\n","      <td>-0.586661</td>\n","      <td>0.269013</td>\n","      <td>4.241005</td>\n","      <td>0.211447</td>\n","      <td>1.073201</td>\n","      <td>-0.202394</td>\n","      <td>0.646930</td>\n","      <td>1.338340</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.277629</td>\n","      <td>-0.159041</td>\n","      <td>-1.923802</td>\n","      <td>-0.311471</td>\n","      <td>-0.936299</td>\n","      <td>-0.486042</td>\n","      <td>-0.205633</td>\n","      <td>0.280182</td>\n","      <td>0.274213</td>\n","      <td>-0.416002</td>\n","      <td>...</td>\n","      <td>-2.899875</td>\n","      <td>-0.604365</td>\n","      <td>4.072822</td>\n","      <td>3.231337</td>\n","      <td>3.867647</td>\n","      <td>3.842431</td>\n","      <td>5.447309</td>\n","      <td>5.358663</td>\n","      <td>4.215949</td>\n","      <td>6.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 23 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52e7305b-ceea-4786-ac64-cb7e86efd353')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-52e7305b-ceea-4786-ac64-cb7e86efd353 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-52e7305b-ceea-4786-ac64-cb7e86efd353');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["df['class'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrjzQalAv8VW","executionInfo":{"status":"ok","timestamp":1659766185654,"user_tz":-330,"elapsed":403,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"dbc0f9dd-0bc8-4cc4-bb21-60ba695fd074"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5.0     4976\n","2.0     4524\n","6.0     3672\n","8.0     3366\n","7.0     3221\n","3.0     2085\n","1.0     1666\n","11.0    1383\n","13.0     569\n","12.0     554\n","14.0     554\n","15.0     456\n","4.0      232\n","10.0     185\n","9.0      184\n","Name: class, dtype: int64"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["\n","copy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"JAH3ejC8tlCi","executionInfo":{"status":"ok","timestamp":1659766403277,"user_tz":-330,"elapsed":621,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"f4c45617-3db8-4ba6-92db-d62a508076c5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                    cat   val\n","0             Rough brick road with gap  1666\n","1                     Concrete sidewalk  4524\n","2                Brick road without gap  2085\n","3              Red paver block sidewalk   232\n","4                     Asphalt surface 1  4976\n","5                     Asphalt surface 2  3672\n","6                                Carpet  3221\n","7                              Linoleum  3366\n","8                         Ceramic tiles   184\n","9                       Up & down curbs   185\n","10       Sidewalk with red paver blocks  1383\n","11  Sidewalk with concrete paver blocks   554\n","12                 Outdoor paving tiles   569\n","13               Embedded stone texture   554\n","14              Striped concret texture   456"],"text/html":["\n","  <div id=\"df-527f51ad-8e1b-41b3-9dd5-5d336a5346f7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cat</th>\n","      <th>val</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Rough brick road with gap</td>\n","      <td>1666</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Concrete sidewalk</td>\n","      <td>4524</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Brick road without gap</td>\n","      <td>2085</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Red paver block sidewalk</td>\n","      <td>232</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Asphalt surface 1</td>\n","      <td>4976</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Asphalt surface 2</td>\n","      <td>3672</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Carpet</td>\n","      <td>3221</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Linoleum</td>\n","      <td>3366</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Ceramic tiles</td>\n","      <td>184</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Up &amp; down curbs</td>\n","      <td>185</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Sidewalk with red paver blocks</td>\n","      <td>1383</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Sidewalk with concrete paver blocks</td>\n","      <td>554</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Outdoor paving tiles</td>\n","      <td>569</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Embedded stone texture</td>\n","      <td>554</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Striped concret texture</td>\n","      <td>456</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-527f51ad-8e1b-41b3-9dd5-5d336a5346f7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-527f51ad-8e1b-41b3-9dd5-5d336a5346f7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-527f51ad-8e1b-41b3-9dd5-5d336a5346f7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","sns.set_style(\"darkgrid\")\n","sns.set(rc={'figure.figsize':(11.7,8.27)})\n","copy = pd.DataFrame({'cat': ['Rough brick road with gap', 'Concrete sidewalk','Brick road without gap', 'Red paver block sidewalk','Asphalt surface 1', \n","                             'Asphalt surface 2','Carpet','Linoleum','Ceramic tiles', 'Up & down curbs','Sidewalk with red paver blocks','Sidewalk with concrete paver blocks',  \n","                             'Outdoor paving tiles', 'Embedded stone texture','Striped concrete texture'],\n","                     'val': [1666,4524,2085,232,4976,3672,3221,3366,184,185,1383,554,569,554,456]})\n","fig = sns.barplot(x=\"val\",y=\"cat\",palette=\"rocket\", data=copy)\n","plt.xlabel(\"Number of Datapoints\")\n","plt.ylabel(\"Surfaces\")\n","# plt.title(\"Class Distribution of Wheelchair dataset\")\n","plt.show(fig)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"id":"-kGYbuyKoUwa","executionInfo":{"status":"ok","timestamp":1659767788091,"user_tz":-330,"elapsed":1317,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"498cfbf8-5bb4-47e4-e17f-2fc998f7789e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 842.4x595.44 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# Number of layers"],"metadata":{"id":"oG8cm6fODy99"}},{"cell_type":"code","source":["#Run this cell for CASE\n","\n","df = pd.read_csv('/content/drive/MyDrive/HEXR/Data/CASE_2class.csv')\n","\n","ohe = OneHotEncoder()\n","#Choose either class1 or class2 to select either valence or arousal\n","df_ohe = pd.DataFrame(ohe.fit_transform(df[['class2']]).toarray())\n","df = df.join(df_ohe)\n","\n","df.drop('class1', axis=1, inplace=True)\n","df.drop('class2', axis=1, inplace=True)\n","df.drop('Unnamed: 0', axis=1, inplace=True)\n","df.drop('valence', axis=1, inplace=True)\n","df.drop('arousal', axis=1, inplace=True)\n","X = df.loc[:,:'emg_trap']\n","y = df.iloc[:,8:]\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","\n","X[['ecg', 'bvp', 'gsr', 'rsp', 'skt', 'emg_zygo', 'emg_coru', 'emg_trap']] = scaler.fit_transform(X[['ecg', 'bvp', 'gsr', 'rsp', 'skt', 'emg_zygo', 'emg_coru', 'emg_trap']])\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","\"\"\"\n","Split used in accordance with VIME @ Neurips 2020 for comparison:\n","15% :- Test \n","10% of 85% = 8.5% :- Labelled dataset\n","90% of 85% = 76.5% :- Unlabelled dataset\n","\"\"\"\n","X_L, X_U, y_L, y_test = train_test_split(X,y,test_size=0.15,random_state=7) \n","\n","#converting to numpy arrays\n","X_L = X_L.iloc[:, :].values\n","y_L = y_L.iloc[:, :].values\n","X_U = X_U.iloc[:,:].values\n","y_test = y_test.iloc[:,:].values\n","X_L.shape, X_U.shape, y_L.shape, y_test.shape\n","\n","\n","x_train = X_L\n","y_train = y_L\n","x_test = X_U\n","y_test = y_test"],"metadata":{"id":"GQO9fNyQD2M3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(x_train[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htZCBYv2WFCJ","executionInfo":{"status":"ok","timestamp":1660404076958,"user_tz":-330,"elapsed":847,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"88cf5e5c-40be-4b16-c4df-8152bd7391c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# Experimental parameters\n","label_no = 1000  \n","model_sets = ['logit','mlp']\n","\n","#reconstuction loss is log cosh\n","#recon_loss = log_cosh\n","\n","# Hyper-parameters\n","p_m = 0.3\n","alpha = 2.0\n","K = 3\n","beta = 1.0\n","label_data_rate = 0.1\n","\n","# Metric\n","metric1 = 'acc'\n","metric2 = 'auc'\n","  \n","# Define output\n","results = np.zeros([len(model_sets)+2])"],"metadata":{"id":"iWE0eyeED2PS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Divide labeled and unlabeled data\n","idx = np.random.permutation(len(y_train))\n","\n","# Label data : Unlabeled data = label_data_rate:(1-label_data_rate)\n","label_idx = idx[:int(len(idx)*label_data_rate)]\n","unlab_idx = idx[int(len(idx)*label_data_rate):]\n","\n","# Unlabeled data\n","x_unlab = x_train[unlab_idx, :]\n","\n","# Labeled data\n","x_train = x_train[label_idx, :] \n","y_train = y_train[label_idx, :]"],"metadata":{"id":"NYpQudc6D61V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlp_parameters = dict()\n","mlp_parameters['hidden_dim'] = 100\n","mlp_parameters['epochs'] = 100\n","mlp_parameters['activation'] = 'relu'\n","mlp_parameters['batch_size'] = 128\n","mlp_parameters['num_layers'] = 5"],"metadata":{"id":"ef9wM9UND63x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","\n","def mlp(x_train, y_train, x_test, parameters):\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  act_fn = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","\n","  # Build model\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = act_fn))\n","  for i in range(0,parameters['num_layers']):\n","    model.add(Dense(hidden_dim, activation = act_fn))  \n","    # model.add(Dense(hidden_dim, activation = act_fn))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  \n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam', \n","                metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', \n","                     verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid), \n","            epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","  \n","  return y_test_hat"],"metadata":{"id":"6ngAQ-76EA87"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Self supervised training of encoder - 90% of train data.\n","\n","# mlp_parameters = dict()\n","# mlp_parameters['hidden_dim'] = 100\n","# mlp_parameters['epochs'] = 100\n","# mlp_parameters['activation'] = 'relu'\n","# mlp_parameters['batch_size'] = 128\n","  \n","# Train VIME-Self\n","vime_self_parameters = dict()\n","vime_self_parameters['batch_size'] = 128\n","vime_self_parameters['epochs'] = 15\n","vime_self_encoder = vime_self(x_unlab, p_m, alpha, vime_self_parameters)\n","    \n","# Save encoder\n","if not os.path.exists('save_model'):\n","  os.makedirs('save_model')\n","\n","file_name = '../Models/arousal_CASE_encoder.h5'\n","    \n","vime_self_encoder.save(file_name)  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knZZ-e46Ac2J","executionInfo":{"status":"ok","timestamp":1660404523288,"user_tz":-330,"elapsed":386312,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"ee4b9ddb-bef2-4737-ab59-e895b1e80981"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","8792/8792 [==============================] - 28s 3ms/step - loss: 0.6214 - mask_loss: 0.6126 - feature_loss: 0.0044\n","Epoch 2/15\n","8792/8792 [==============================] - 34s 4ms/step - loss: 0.6186 - mask_loss: 0.6110 - feature_loss: 0.0038\n","Epoch 3/15\n","8792/8792 [==============================] - 38s 4ms/step - loss: 0.6181 - mask_loss: 0.6105 - feature_loss: 0.0038\n","Epoch 4/15\n","8792/8792 [==============================] - 38s 4ms/step - loss: 0.6169 - mask_loss: 0.6093 - feature_loss: 0.0038\n","Epoch 5/15\n","8792/8792 [==============================] - 31s 4ms/step - loss: 0.6164 - mask_loss: 0.6087 - feature_loss: 0.0038\n","Epoch 6/15\n","8792/8792 [==============================] - 20s 2ms/step - loss: 0.6158 - mask_loss: 0.6081 - feature_loss: 0.0038\n","Epoch 7/15\n","8792/8792 [==============================] - 20s 2ms/step - loss: 0.6149 - mask_loss: 0.6073 - feature_loss: 0.0038\n","Epoch 8/15\n","8792/8792 [==============================] - 20s 2ms/step - loss: 0.6142 - mask_loss: 0.6066 - feature_loss: 0.0038\n","Epoch 9/15\n","8792/8792 [==============================] - 20s 2ms/step - loss: 0.6135 - mask_loss: 0.6059 - feature_loss: 0.0038\n","Epoch 10/15\n","8792/8792 [==============================] - 24s 3ms/step - loss: 0.6129 - mask_loss: 0.6052 - feature_loss: 0.0038\n","Epoch 11/15\n","8792/8792 [==============================] - 20s 2ms/step - loss: 0.6122 - mask_loss: 0.6046 - feature_loss: 0.0038\n","Epoch 12/15\n","8792/8792 [==============================] - 20s 2ms/step - loss: 0.6117 - mask_loss: 0.6040 - feature_loss: 0.0038\n","Epoch 13/15\n","8792/8792 [==============================] - 20s 2ms/step - loss: 0.6114 - mask_loss: 0.6037 - feature_loss: 0.0039\n","Epoch 14/15\n","8792/8792 [==============================] - 20s 2ms/step - loss: 0.6112 - mask_loss: 0.6035 - feature_loss: 0.0039\n","Epoch 15/15\n","8792/8792 [==============================] - 23s 3ms/step - loss: 0.6111 - mask_loss: 0.6033 - feature_loss: 0.0039\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n"]}]},{"cell_type":"code","source":["logistic_supervised_acc = []\n","logistic_supervised_auc = []\n","mlp_supervised_acc = []\n","mlp_supervised_auc = []\n","self_supervised_acc = []\n","self_supervised_auc = []\n","\n","# mlp_parameters = dict()\n","# mlp_parameters['hidden_dim'] = 100\n","# mlp_parameters['epochs'] = 100\n","# mlp_parameters['activation'] = 'relu'\n","# mlp_parameters['batch_size'] = 128\n","\n","from keras.models import load_model\n","vime_self_encoder = load_model('../Models/arousal_CASE_encoder.h5')\n","\n","# for label_no in tqdm([1000,20000,40000,60000,80000,100000, len(label_idx)]):\n","  # x_t = x_train[:label_no, :]\n","  # y_t = y_train[:label_no, :]  \n","\n","# y_test_hat = logit(x_train, y_train, x_test)\n","# logistic_supervised_acc.append(perf_metric(metric1, y_test, y_test_hat))\n","# logistic_supervised_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","\n","y_test_hat = mlp(x_train, y_train, x_test, mlp_parameters)\n","mlp_supervised_acc.append(perf_metric(metric1, y_test, y_test_hat))\n","mlp_supervised_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","\n","  # Test VIME-Self\n","x_train_hat = vime_self_encoder.predict(x_train)\n","x_test_hat = vime_self_encoder.predict(x_test)\n","        \n","y_test_hat = mlp(x_train_hat, y_train, x_test_hat, mlp_parameters)\n","self_supervised_acc.append(perf_metric(metric1, y_test, y_test_hat))\n","self_supervised_auc.append(perf_metric(metric2, y_test, y_test_hat))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bck4ppF4BpDR","executionInfo":{"status":"ok","timestamp":1660405353090,"user_tz":-330,"elapsed":795983,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"9a36d4d5-4f0a-4dba-c1e4-a30ed950c5f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}]},{"cell_type":"code","source":["self_supervised_acc"],"metadata":{"id":"IxHXt3gtyUJw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### test"],"metadata":{"id":"9G2XQHPiyVUg"}},{"cell_type":"code","source":["test_acc = []\n","test_auc = []"],"metadata":{"id":"8FOdEgj6c9mm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test_hat = mlp(x_train, y_train, x_test, mlp_parameters)\n","test_acc.append(perf_metric(metric1, y_test, y_test_hat))\n","test_auc.append(perf_metric(metric2, y_test, y_test_hat))"],"metadata":{"id":"HiYIOqk2c9mo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtYNbhe8dESY","executionInfo":{"status":"ok","timestamp":1659794586004,"user_tz":-330,"elapsed":806,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"580bf8ff-a8fc-4c44-d1d3-5b3efa55c7db"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.8098384728340675]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["for num in [1,2,3,4,5]:\n","  mlp_parameters = dict()\n","  mlp_parameters['hidden_dim'] = 100\n","  mlp_parameters['epochs'] = 100\n","  mlp_parameters['activation'] = 'relu'\n","  mlp_parameters['batch_size'] = 128\n","  mlp_parameters['num_layers'] = num\n","  y_test_hat = mlp(x_train, y_train, x_test, mlp_parameters)\n","  test_acc.append(perf_metric(metric1, y_test, y_test_hat))\n","  test_auc.append(perf_metric(metric2, y_test, y_test_hat))"],"metadata":{"id":"nYP2ousWc9mp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659796968206,"user_tz":-330,"elapsed":582,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"86a6cde6-8bef-48d1-f723-0117fedd1cee","id":"5C88t-Q5c9mp"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7304572070847156,\n"," 0.8050388861695763,\n"," 0.8399639237867333,\n"," 0.8629783724007904,\n"," 0.8795707111908776]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["test_auc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659796970324,"user_tz":-330,"elapsed":4,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"bac3c216-84cc-43ff-89fe-08ae16b84754","id":"v4ikxk_pc9mp"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7616231261866535,\n"," 0.8668989689805209,\n"," 0.9095225465013044,\n"," 0.9288495973005831,\n"," 0.9469470689578086]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","plt.style.use('ggplot')\n","\n","number_data = [1,2,3,4,5]\n","acc = np.array([0.7304572070847156,\n"," 0.8050388861695763,\n"," 0.8399639237867333,\n"," 0.8629783724007904,\n"," 0.8795707111908776])\n","auc = np.array([0.7616231261866535,\n"," 0.8668989689805209,\n"," 0.9095225465013044,\n"," 0.9288495973005831,\n"," 0.9469470689578086])\n","\n","plt.figure(figsize = (10,7))\n","plt.title(\"Number of hidden layers in the predictor vs Accuracy for Arousal prediction\")\n","plt.xlabel(\"Number of hidden layers in the predictor\")\n","plt.ylabel(\"Accuracy\")\n","plt.plot(number_data, acc*100, '-')\n","plt.legend()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"id":"pbqLuBVjEA_d","executionInfo":{"status":"ok","timestamp":1659797761936,"user_tz":-330,"elapsed":826,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"e32bbfc8-28d1-4ec7-b0b3-1068350f884c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f92dea43d50>"]},"metadata":{},"execution_count":21},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x504 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","plt.style.use('ggplot')\n","\n","number_data = [1,2,3,4,5]\n","acc = np.array([0.7304572070847156,\n"," 0.8050388861695763,\n"," 0.8399639237867333,\n"," 0.8629783724007904,\n"," 0.8795707111908776])\n","auc = np.array([0.7616231261866535,\n"," 0.8668989689805209,\n"," 0.9095225465013044,\n"," 0.9288495973005831,\n"," 0.9469470689578086])\n","\n","plt.figure(figsize = (10,7))\n","plt.title(\"Number of hidden layers in the predictor vs AUC for Arousal prediction\")\n","plt.xlabel(\"Number of hidden layers in the predictor\")\n","plt.ylabel(\"AUC\")\n","plt.plot(number_data, auc, '-')\n","plt.legend()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":497},"id":"m2xe26EdqFrw","executionInfo":{"status":"ok","timestamp":1659797809161,"user_tz":-330,"elapsed":824,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"f4c35e98-70fa-4b28-e07b-ba58a2da912d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f92de794b50>"]},"metadata":{},"execution_count":22},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x504 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# CASE - 80:20 tests - Arousal"],"metadata":{"id":"xr0Fc32b_9J3"}},{"cell_type":"code","source":["import os\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd \n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","import supervised_models\n","import vime_self\n","import hexr_self\n","import utils\n","from supervised_models import logit, mlp\n","from utils import mask_generator, pretext_generator\n","from hexr_self import hexr_self\n","from vime_self import vime_self\n","from utils import perf_metric\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend\n","\n","#to load VIME original\n","\n","# from supervised_models import logit, mlp\n","# from vime_utils import mask_generator, pretext_generator\n","# from vime_self import vime_self\n","# from vime_utils import perf_metric"],"metadata":{"id":"r5FkbVHESrOb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Arousal"],"metadata":{"id":"3VZuVf3H4tbN"}},{"cell_type":"code","source":["#Run this cell for CASE\n","\n","df = pd.read_csv('/content/drive/MyDrive/HEXR/Data/CASE_2class.csv')\n","\n","ohe = OneHotEncoder()\n","#Choose either class1 or class2 to select either valence or arousal\n","df_ohe = pd.DataFrame(ohe.fit_transform(df[['class2']]).toarray())\n","df = df.join(df_ohe)\n","\n","df.drop('class1', axis=1, inplace=True)\n","df.drop('class2', axis=1, inplace=True)\n","df.drop('Unnamed: 0', axis=1, inplace=True)\n","df.drop('valence', axis=1, inplace=True)\n","df.drop('arousal', axis=1, inplace=True)\n","X = df.loc[:,:'emg_trap']\n","y = df.iloc[:,8:]\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","\"\"\"\n","Split used in accordance with VIME @ Neurips 2020 for comparison:\n","20% :- Test \n","10% of 80% = 8% :- Labelled dataset\n","90% of 80% = 72% :- Unlabelled dataset\n","\"\"\"\n","X_L, X_U, y_L, y_test = train_test_split(X,y,test_size=0.20,random_state=7) \n","\n","#converting to numpy arrays\n","X_L = X_L.iloc[:, :].values\n","y_L = y_L.iloc[:, :].values\n","X_U = X_U.iloc[:,:].values\n","y_test = y_test.iloc[:,:].values\n","X_L.shape, X_U.shape, y_L.shape, y_test.shape\n","\n","\n","x_train = X_L\n","y_train = y_L\n","x_test = X_U\n","y_test = y_test"],"metadata":{"id":"51GQq2_Ol0sm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_L.shape, X_U.shape, y_L.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hQAeVBV8R1b","executionInfo":{"status":"ok","timestamp":1661518977361,"user_tz":-330,"elapsed":4,"user":{"displayName":"Hrithik Nambiar","userId":"12050495114928382036"}},"outputId":"12c22ab1-c534-4420-ba2f-e7c1c3dbf109"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1176768, 8), (294192, 8), (1176768, 2), (294192, 2))"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Experimental parameters\n","label_no = 1000  \n","model_sets = ['logit','mlp']\n","\n","#reconstuction loss is log cosh\n","#recon_loss = log_cosh\n","\n","# Hyper-parameters\n","p_m = 0.3\n","alpha = 2.0\n","K = 3\n","beta = 1.0\n","label_data_rate = 0.1\n","\n","# Metric\n","metric1 = 'acc'\n","metric2 = 'auc'"],"metadata":{"id":"yVg9pWtyl0uz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Divide labeled and unlabeled data\n","idx = np.random.permutation(len(y_train))\n","\n","# Label data : Unlabeled data = label_data_rate:(1-label_data_rate)\n","label_idx = idx[:int(len(idx)*label_data_rate)]\n","unlab_idx = idx[int(len(idx)*label_data_rate):]\n","\n","# Unlabeled data\n","x_unlab = x_train[unlab_idx, :]\n","\n","# Labeled data\n","x_train = x_train[label_idx, :] \n","y_train = y_train[label_idx, :]"],"metadata":{"id":"KdU5gq1Jl8aO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape, x_unlab.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TjeBMThu82Er","executionInfo":{"status":"ok","timestamp":1661518981535,"user_tz":-330,"elapsed":4,"user":{"displayName":"Hrithik Nambiar","userId":"12050495114928382036"}},"outputId":"92cd5b0b-50d0-4a2e-a94c-8712bdcf2f86"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((117676, 8), (1059092, 8))"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["len(x_train[0, :])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xW0p3_vgoLGJ","executionInfo":{"status":"ok","timestamp":1661518988443,"user_tz":-330,"elapsed":404,"user":{"displayName":"Hrithik Nambiar","userId":"12050495114928382036"}},"outputId":"1fa4715b-1a21-4583-c3ce-bd2d59f26dbe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["\"\"\" \n","Scaling for Original VIME\n","\"\"\"\n","\n","\"\"\"Min-Max scaling only for original VIME\"\"\"\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","\n","X[['ecg', 'bvp', 'gsr', 'rsp', 'skt', 'emg_zygo', 'emg_coru', 'emg_trap']] = scaler.fit_transform(X[['ecg', 'bvp', 'gsr', 'rsp', 'skt', 'emg_zygo', 'emg_coru', 'emg_trap']])\n","\n","from sklearn.model_selection import train_test_split\n","\n","\"\"\"\n","Split used in accordance with VIME @ Neurips 2020 for comparison:\n","20% :- Test \n","10% of 80% = 8% :- Labelled dataset\n","90% of 80% = 72% :- Unlabelled dataset\n","\"\"\"\n","X_L_vime, X_U_vime, y_L_vime, y_test_vime = train_test_split(X,y,test_size=0.20,random_state=7) \n","\n","#converting to numpy arrays\n","X_L_vime = X_L_vime.iloc[:, :].values\n","y_L_vime = y_L_vime.iloc[:, :].values\n","X_U_vime = X_U_vime.iloc[:,:].values\n","y_test_vime = y_test_vime.iloc[:,:].values\n","\n","x_train_vime = X_L_vime\n","y_train_vime = y_L_vime\n","x_test_vime = X_U_vime\n","y_test_vime = y_test_vime\n","\n","# Unlabeled data\n","x_unlab_vime = x_train_vime[unlab_idx, :]\n","\n","# Labeled data\n","x_train_vime = x_train_vime[label_idx, :] \n","y_train_vime = y_train_vime[label_idx, :]"],"metadata":{"id":"U0g8lftNiCF1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlp_parameters = dict()\n","mlp_parameters['hidden_dim'] = 100\n","mlp_parameters['epochs'] = 100\n","mlp_parameters['activation'] = 'relu'\n","mlp_parameters['batch_size'] = 128\n","mlp_parameters['num_layers'] = 5"],"metadata":{"id":"-W6qCQVxnKTw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","MLP suggested by HEXR\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import backend\n","\n","from tensorflow.keras.layers import LeakyReLU\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","import math\n","\n","\"\"\"\n","Parameterized Activation functions.\n","\"\"\"\n","\n","\"\"\"\n","Initializing parameters. We observe that a initialization from Uniform distribution \n","yield a better result than normal distribution.\n","\"\"\"\n","\n","initializer0 = keras.initializers.RandomUniform(minval = -1, maxval =1)\n","initializer1 = keras.initializers.RandomUniform(minval = 0.5, maxval =3) \n","\n","def param_elliot_function( signal, k1, k2 ,  derivative=False ):\n","    \"\"\" A parameterized version of Elliot activation function \"\"\"\n","    s = 1 # steepness\n","    \n","    abs_signal = (1 + tf.math.abs(signal * s))\n","    if derivative:\n","        return 0.5 * s / abs_signal**2\n","    else:\n","        # Return the activation signal\n","        return (k1*(signal * s) / abs_signal + k2)\n","\n","class ParamElliotfn(keras.layers.Layer):\n","    def __init__(self, trainable = True):\n","        super(ParamElliotfn, self).__init__()\n","        self.k1 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","        self.k2 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","    def call(self, inputs):\n","        return param_elliot_function(inputs, self.k1, self.k2 )\n","\n","\n","def hexr_mlp(x_train, y_train, x_test, parameters):\n","\n","  print(\"HEXR MLP\")\n","\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  # K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  # Arelu = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","  \n","  print(\"Supervised MLP training sing Parameterized Elliot activation.\") \n","  Elliot = ParamElliotfn()\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = Elliot))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = Elliot))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # print(\"Balancing classes\") \n","  # from sklearn.utils.class_weight import compute_sample_weight\n","  # sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n","\n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid),epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","\n","  \n","  return y_test_hat"],"metadata":{"id":"LPygI859fxsL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain (VIME) Codebase.\n","\n","Reference: Jinsung Yoon, Yao Zhang, James Jordon, Mihaela van der Schaar, \n","\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain,\" \n","Neural Information Processing Systems (NeurIPS), 2020.\n","Paper link: TBD\n","Last updated Date: October 11th 2020\n","Code author: Jinsung Yoon (jsyoon0823@gmail.com)\n","-----------------------------\n","\n","supervised_models.py\n","- Train supervised model and return predictions on the testing data\n","\n","(1) logit: logistic regression\n","(2) xgb_model: XGBoost model\n","(3) mlp: multi-layer perceptrons\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","  \n","#%% \n","def vime_mlp(x_train, y_train, x_test, parameters):\n","  print(\"VIME MLP\")\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  act_fn = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","\n","  # Build model\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = act_fn))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = act_fn))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  \n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam', \n","                metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', \n","                     verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid), \n","            epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","  \n","  return y_test_hat"],"metadata":{"id":"VxjilRC_i0E7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_HEXR_acc = []\n","results_HEXR_auc = []\n","results_VIME_acc = []\n","results_VIME_auc = []\n","hexrSup_test_acc = []\n","hexrSup_test_auc = []\n","vimeSup_test_acc = []\n","vimeSup_test_auc = []\n","\n","\n","for i in range(0,5):\n","\n","  mlp_parameters = dict()\n","  mlp_parameters['hidden_dim'] = 100\n","  mlp_parameters['epochs'] = 100\n","  mlp_parameters['activation'] = 'relu'\n","  mlp_parameters['batch_size'] = 128\n","  mlp_parameters['num_layers'] = 5\n","  \n","  #supervised - HEXR\n","  # y_test_hat = hexr_mlp(x_train, y_train, x_test, mlp_parameters)\n","  # mlp_perf1 = perf_metric(metric1, y_test, y_test_hat)\n","  # hexrSup_test_acc.append(mlp_perf1)\n","  # hexrSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  # print(\"HEXR MLP performance : {}\".format(mlp_perf1))\n","\n","  #supervised - VIME\n","  y_test_hat = vime_mlp(x_train, y_train, x_test, mlp_parameters)\n","  mlp_perf2 = perf_metric(metric1, y_test, y_test_hat)\n","  vimeSup_test_acc.append(mlp_perf2)\n","  vimeSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  print(\"VIME MLP performance : {}\".format(mlp_perf2))\n","\n","  # Train HEXR-Self \n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  hexr_self_encoder = hexr_self(x_unlab, p_m, alpha, vime_self_parameters)\n","    \n","  # Save encoder\n","  if not os.path.exists('save_model'):\n","    os.makedirs('save_model')\n","\n","  file_name = './save_model/HEXR_encoder_model_arousal_{}.h5'.format(i)\n","    \n","  hexr_self_encoder.save(file_name)  \n","          \n","  # Test HEXR-Self\n","  x_train_hat = hexr_self_encoder.predict(x_train)\n","  x_test_hat = hexr_self_encoder.predict(x_test)\n","        \n","  y_test_hat1 = vime_mlp(x_train_hat, y_train, x_test_hat, mlp_parameters)\n","  res = perf_metric(metric1, y_test, y_test_hat1)\n","  results_HEXR_acc.append(perf_metric(metric1, y_test, y_test_hat1))\n","  results_HEXR_auc.append(perf_metric(metric2, y_test, y_test_hat1))\n","        \n","  print('HEXR-Self Performance: ' + str(res))\n","\n","  #Train VIME self\n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  vime_self_encoder = vime_self(x_unlab_vime, p_m, alpha, vime_self_parameters)\n","\n","  file_name = './save_model/VIME_encoder_model_arousal_{}.h5'.format(i)\n","    \n","  vime_self_encoder.save(file_name)  \n","          \n","  # Test VIME-Self\n","  x_train_hat = vime_self_encoder.predict(x_train_vime)\n","  x_test_hat = vime_self_encoder.predict(x_test_vime)\n","        \n","  y_test_hat2 = vime_mlp(x_train_hat, y_train_vime, x_test_hat, mlp_parameters)\n","  res2 = perf_metric(metric1, y_test_vime, y_test_hat2)\n","  results_VIME_acc.append(res2)\n","  results_VIME_auc.append(perf_metric(metric2, y_test_vime, y_test_hat2))\n","        \n","  print('VIME-Self Performance: ' + str(res2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcf9kNR29ieo","outputId":"83cd055d-b51c-4f0b-f9f3-24653cddf30d","executionInfo":{"status":"ok","timestamp":1661525860115,"user_tz":-330,"elapsed":6851683,"user":{"displayName":"Hrithik Nambiar","userId":"12050495114928382036"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME MLP performance : 0.8528308043726546\n","Epoch 1/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 9.0780 - mask_loss: 0.6142 - feature_loss: 4.2319\n","Epoch 2/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 5.0796 - mask_loss: 0.6117 - feature_loss: 2.2339\n","Epoch 3/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.7996 - mask_loss: 0.6117 - feature_loss: 2.0939\n","Epoch 4/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.6749 - mask_loss: 0.6112 - feature_loss: 2.0318\n","Epoch 5/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.6482 - mask_loss: 0.6111 - feature_loss: 2.0186\n","Epoch 6/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.6272 - mask_loss: 0.6110 - feature_loss: 2.0081\n","Epoch 7/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.6073 - mask_loss: 0.6108 - feature_loss: 1.9982\n","Epoch 8/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.5861 - mask_loss: 0.6107 - feature_loss: 1.9877\n","Epoch 9/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.5656 - mask_loss: 0.6105 - feature_loss: 1.9776\n","Epoch 10/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.5153 - mask_loss: 0.6107 - feature_loss: 1.9523\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8664749551313428\n","Epoch 1/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 0.6368 - mask_loss: 0.6120 - feature_loss: 0.0124\n","Epoch 2/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6258 - mask_loss: 0.6099 - feature_loss: 0.0080\n","Epoch 3/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6254 - mask_loss: 0.6096 - feature_loss: 0.0079\n","Epoch 4/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6251 - mask_loss: 0.6093 - feature_loss: 0.0079\n","Epoch 5/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6247 - mask_loss: 0.6089 - feature_loss: 0.0079\n","Epoch 6/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6243 - mask_loss: 0.6085 - feature_loss: 0.0079\n","Epoch 7/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6242 - mask_loss: 0.6084 - feature_loss: 0.0079\n","Epoch 8/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6240 - mask_loss: 0.6082 - feature_loss: 0.0079\n","Epoch 9/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6239 - mask_loss: 0.6081 - feature_loss: 0.0079\n","Epoch 10/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6238 - mask_loss: 0.6080 - feature_loss: 0.0079\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.830321694675586\n","VIME MLP\n","VIME MLP performance : 0.8519878174797412\n","Epoch 1/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 9.7327 - mask_loss: 0.6128 - feature_loss: 4.5600\n","Epoch 2/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 5.6534 - mask_loss: 0.6117 - feature_loss: 2.5209\n","Epoch 3/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 5.0761 - mask_loss: 0.6114 - feature_loss: 2.2323\n","Epoch 4/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.6323 - mask_loss: 0.6114 - feature_loss: 2.0104\n","Epoch 5/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.4974 - mask_loss: 0.6114 - feature_loss: 1.9430\n","Epoch 6/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.4529 - mask_loss: 0.6113 - feature_loss: 1.9208\n","Epoch 7/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.4372 - mask_loss: 0.6112 - feature_loss: 1.9130\n","Epoch 8/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.4237 - mask_loss: 0.6113 - feature_loss: 1.9062\n","Epoch 9/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4113 - mask_loss: 0.6112 - feature_loss: 1.9001\n","Epoch 10/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.4006 - mask_loss: 0.6111 - feature_loss: 1.8947\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8709482242888997\n","Epoch 1/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6341 - mask_loss: 0.6120 - feature_loss: 0.0110\n","Epoch 2/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6262 - mask_loss: 0.6104 - feature_loss: 0.0079\n","Epoch 3/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6259 - mask_loss: 0.6102 - feature_loss: 0.0078\n","Epoch 4/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6255 - mask_loss: 0.6098 - feature_loss: 0.0079\n","Epoch 5/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6250 - mask_loss: 0.6091 - feature_loss: 0.0079\n","Epoch 6/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6241 - mask_loss: 0.6082 - feature_loss: 0.0080\n","Epoch 7/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6234 - mask_loss: 0.6076 - feature_loss: 0.0079\n","Epoch 8/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6225 - mask_loss: 0.6067 - feature_loss: 0.0079\n","Epoch 9/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6223 - mask_loss: 0.6065 - feature_loss: 0.0079\n","Epoch 10/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6222 - mask_loss: 0.6064 - feature_loss: 0.0079\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8407842497416653\n","VIME MLP\n","VIME MLP performance : 0.842789742753032\n","Epoch 1/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 9.6769 - mask_loss: 0.6121 - feature_loss: 4.5324\n","Epoch 2/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 5.5404 - mask_loss: 0.6114 - feature_loss: 2.4645\n","Epoch 3/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 5.3284 - mask_loss: 0.6118 - feature_loss: 2.3583\n","Epoch 4/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 5.1489 - mask_loss: 0.6114 - feature_loss: 2.2687\n","Epoch 5/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 5.0565 - mask_loss: 0.6112 - feature_loss: 2.2227\n","Epoch 6/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 5.0128 - mask_loss: 0.6111 - feature_loss: 2.2008\n","Epoch 7/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.9831 - mask_loss: 0.6111 - feature_loss: 2.1860\n","Epoch 8/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.9569 - mask_loss: 0.6111 - feature_loss: 2.1729\n","Epoch 9/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.9246 - mask_loss: 0.6111 - feature_loss: 2.1567\n","Epoch 10/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.8957 - mask_loss: 0.6111 - feature_loss: 2.1423\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8421541034426497\n","Epoch 1/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6342 - mask_loss: 0.6123 - feature_loss: 0.0110\n","Epoch 2/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6266 - mask_loss: 0.6107 - feature_loss: 0.0080\n","Epoch 3/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6261 - mask_loss: 0.6102 - feature_loss: 0.0079\n","Epoch 4/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6247 - mask_loss: 0.6090 - feature_loss: 0.0079\n","Epoch 5/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6243 - mask_loss: 0.6086 - feature_loss: 0.0079\n","Epoch 6/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6242 - mask_loss: 0.6085 - feature_loss: 0.0079\n","Epoch 7/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6241 - mask_loss: 0.6084 - feature_loss: 0.0079\n","Epoch 8/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6239 - mask_loss: 0.6082 - feature_loss: 0.0078\n","Epoch 9/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6237 - mask_loss: 0.6080 - feature_loss: 0.0078\n","Epoch 10/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6234 - mask_loss: 0.6077 - feature_loss: 0.0078\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8321300375265133\n","VIME MLP\n","VIME MLP performance : 0.8542414477620057\n","Epoch 1/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 9.5441 - mask_loss: 0.6136 - feature_loss: 4.4652\n","Epoch 2/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 5.2892 - mask_loss: 0.6114 - feature_loss: 2.3389\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.9086 - mask_loss: 0.6125 - feature_loss: 2.1481\n","Epoch 4/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.6161 - mask_loss: 0.6116 - feature_loss: 2.0022\n","Epoch 5/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.5085 - mask_loss: 0.6114 - feature_loss: 1.9486\n","Epoch 6/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.3946 - mask_loss: 0.6113 - feature_loss: 1.8916\n","Epoch 7/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.3173 - mask_loss: 0.6112 - feature_loss: 1.8530\n","Epoch 8/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.2717 - mask_loss: 0.6112 - feature_loss: 1.8302\n","Epoch 9/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.2507 - mask_loss: 0.6112 - feature_loss: 1.8197\n","Epoch 10/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.2386 - mask_loss: 0.6112 - feature_loss: 1.8137\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8782903681949203\n","Epoch 1/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6365 - mask_loss: 0.6125 - feature_loss: 0.0120\n","Epoch 2/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6259 - mask_loss: 0.6100 - feature_loss: 0.0079\n","Epoch 3/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6252 - mask_loss: 0.6094 - feature_loss: 0.0079\n","Epoch 4/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6246 - mask_loss: 0.6090 - feature_loss: 0.0078\n","Epoch 5/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6243 - mask_loss: 0.6086 - feature_loss: 0.0078\n","Epoch 6/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6240 - mask_loss: 0.6083 - feature_loss: 0.0079\n","Epoch 7/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6239 - mask_loss: 0.6081 - feature_loss: 0.0079\n","Epoch 8/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6237 - mask_loss: 0.6079 - feature_loss: 0.0079\n","Epoch 9/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6237 - mask_loss: 0.6078 - feature_loss: 0.0079\n","Epoch 10/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6236 - mask_loss: 0.6077 - feature_loss: 0.0079\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8347337793005928\n","VIME MLP\n","VIME MLP performance : 0.8557914559199434\n","Epoch 1/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 8.4240 - mask_loss: 0.6149 - feature_loss: 3.9045\n","Epoch 2/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 5.0926 - mask_loss: 0.6128 - feature_loss: 2.2399\n","Epoch 3/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.6679 - mask_loss: 0.6112 - feature_loss: 2.0283\n","Epoch 4/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.5673 - mask_loss: 0.6110 - feature_loss: 1.9781\n","Epoch 5/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.5246 - mask_loss: 0.6110 - feature_loss: 1.9568\n","Epoch 6/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.5008 - mask_loss: 0.6110 - feature_loss: 1.9449\n","Epoch 7/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.4819 - mask_loss: 0.6110 - feature_loss: 1.9355\n","Epoch 8/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.4659 - mask_loss: 0.6109 - feature_loss: 1.9275\n","Epoch 9/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.4489 - mask_loss: 0.6109 - feature_loss: 1.9190\n","Epoch 10/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 4.4310 - mask_loss: 0.6109 - feature_loss: 1.9101\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8725016315875347\n","Epoch 1/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6332 - mask_loss: 0.6124 - feature_loss: 0.0104\n","Epoch 2/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6252 - mask_loss: 0.6093 - feature_loss: 0.0079\n","Epoch 3/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6246 - mask_loss: 0.6089 - feature_loss: 0.0078\n","Epoch 4/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6244 - mask_loss: 0.6088 - feature_loss: 0.0078\n","Epoch 5/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6243 - mask_loss: 0.6087 - feature_loss: 0.0078\n","Epoch 6/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6242 - mask_loss: 0.6086 - feature_loss: 0.0078\n","Epoch 7/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6241 - mask_loss: 0.6085 - feature_loss: 0.0078\n","Epoch 8/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6239 - mask_loss: 0.6083 - feature_loss: 0.0078\n","Epoch 9/10\n","8275/8275 [==============================] - 27s 3ms/step - loss: 0.6237 - mask_loss: 0.6080 - feature_loss: 0.0078\n","Epoch 10/10\n","8275/8275 [==============================] - 28s 3ms/step - loss: 0.6234 - mask_loss: 0.6076 - feature_loss: 0.0079\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8437143090226791\n"]}]},{"cell_type":"code","source":["results_HEXR_acc, results_VIME_acc, vimeSup_test_acc"],"metadata":{"id":"8SqCBpf7yImg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661525860115,"user_tz":-330,"elapsed":33,"user":{"displayName":"Hrithik Nambiar","userId":"12050495114928382036"}},"outputId":"7df9bbba-25f0-41b4-a5e7-6704c2a622cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.8664749551313428,\n","  0.8709482242888997,\n","  0.8421541034426497,\n","  0.8782903681949203,\n","  0.8725016315875347],\n"," [0.830321694675586,\n","  0.8407842497416653,\n","  0.8321300375265133,\n","  0.8347337793005928,\n","  0.8437143090226791],\n"," [0.8528308043726546,\n","  0.8519878174797412,\n","  0.842789742753032,\n","  0.8542414477620057,\n","  0.8557914559199434])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["results_HEXR_auc, results_VIME_auc, vimeSup_test_auc"],"metadata":{"id":"BBunLvBByImh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661525860116,"user_tz":-330,"elapsed":13,"user":{"displayName":"Hrithik Nambiar","userId":"12050495114928382036"}},"outputId":"12096725-033b-411f-8d2b-3cb7736ce000"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.9318493748623498,\n","  0.9363186295942663,\n","  0.9101540488094058,\n","  0.9412149383164254,\n","  0.9393188214347552],\n"," [0.8988885657177801,\n","  0.9127806885681823,\n","  0.9014813336765326,\n","  0.9047486201598045,\n","  0.9151798961523161],\n"," [0.919431777258732,\n","  0.9170922942889717,\n","  0.9106608405232736,\n","  0.9198239499789789,\n","  0.9221062750783958])"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["# Wheelchair"],"metadata":{"id":"S0rbPh0rnpB8"}},{"cell_type":"code","source":["#Run this cell for Wheelchair\n","\n","df_mw = pd.read_excel('/content/drive/MyDrive/WheelShare/Code/wheelchair.xlsx')\n","\n","ohe = OneHotEncoder()\n","#Choose either class1 or class2 to select either valence or arousal\n","df_ohe = pd.DataFrame(ohe.fit_transform(df_mw[['class']]).toarray())\n","df_mw = df_mw.join(df_ohe)\n","\n","df_mw.drop('class', axis=1, inplace=True)\n","X = df_mw.loc[:,:'gyr_maxabssum']\n","y = df_mw.iloc[:,22:]\n","\n","\n","# from sklearn.preprocessing import MinMaxScaler\n","\n","\n","# scaler = MinMaxScaler()\n","\n","\n","# X = scaler.fit_transform(X)\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_L_mw, X_U_mw, y_L_mw, y_test_mw = train_test_split(X,y,test_size=0.20,random_state=7) #80-20 split\n","\n","#converting to numpy arrays\n","X_L_mw = X_L_mw.iloc[:, :].values\n","y_L_mw = y_L_mw.iloc[:, :].values\n","X_U_mw = X_U_mw.iloc[:,:].values\n","y_test_mw = y_test_mw.iloc[:,:].values\n","X_L_mw.shape, X_U_mw.shape, y_L_mw.shape, y_test_mw.shape\n","\n","\n","x_train = X_L_mw\n","y_train = y_L_mw\n","x_test = X_U_mw\n","y_test = y_test_mw"],"metadata":{"id":"bGj1bz5O-kLu","executionInfo":{"status":"ok","timestamp":1661594720917,"user_tz":-330,"elapsed":16947,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Experimental parameters\n","label_no = 1000  \n","model_sets = ['logit','mlp']\n","\n","#reconstuction loss is log cosh\n","#recon_loss = log_cosh\n","\n","# Hyper-parameters\n","p_m = 0.3\n","alpha = 2.0\n","K = 3\n","beta = 1.0\n","label_data_rate = 0.1\n","\n","# Metric\n","metric1 = 'acc'\n","metric2 = 'auc'"],"metadata":{"id":"wiH_7N1Sodl5","executionInfo":{"status":"ok","timestamp":1661594730034,"user_tz":-330,"elapsed":644,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Divide labeled and unlabeled data\n","idx = np.random.permutation(len(y_train))\n","\n","# Label data : Unlabeled data = label_data_rate:(1-label_data_rate)\n","label_idx = idx[:int(len(idx)*label_data_rate)]\n","unlab_idx = idx[int(len(idx)*label_data_rate):]\n","\n","# Unlabeled data\n","x_unlab = x_train[unlab_idx, :]\n","\n","# Labeled data\n","x_train = x_train[label_idx, :] \n","y_train = y_train[label_idx, :]"],"metadata":{"id":"EDr57THaodl6","executionInfo":{"status":"ok","timestamp":1661594733247,"user_tz":-330,"elapsed":1,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["x_train.shape, x_unlab.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661594734002,"user_tz":-330,"elapsed":8,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"33f75632-fad0-43fd-fbba-dd0483b6b59d","id":"45NmLwneodl6"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2210, 22), (19891, 22))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["len(x_train[0, :])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661594734003,"user_tz":-330,"elapsed":5,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"e225ea2b-2ce3-4021-a38e-38c519dfb6b1","id":"-JcVuhtDodl6"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\"\"\" \n","Scaling for Original VIME\n","\"\"\"\n","\n","\"\"\"Min-Max scaling only for original VIME\"\"\"\n","\n","# from sklearn.preprocessing import MinMaxScaler\n","# scaler = MinMaxScaler()\n","# X = scaler.fit_transform(X)\n","\n","# from sklearn.model_selection import train_test_split\n","\n","# \"\"\"\n","# Split used in accordance with VIME @ Neurips 2020 for comparison:\n","# 20% :- Test \n","# 10% of 80% = 8% :- Labelled dataset\n","# 90% of 80% = 72% :- Unlabelled dataset\n","# \"\"\"\n","# X_L_vime, X_U_vime, y_L_vime, y_test_vime = train_test_split(X,y,test_size=0.20,random_state=7) \n","\n","# #converting to numpy arrays\n","# # X_L_vime = X_L_vime.iloc[:, :].values\n","# y_L_vime = y_L_vime.iloc[:, :].values\n","# # X_U_vime = X_U_vime.iloc[:,:].values\n","# y_test_vime = y_test_vime.iloc[:,:].values\n","\n","\n","x_train_vime = X_L_mw\n","y_train_vime = y_L_mw\n","x_test_vime = X_U_mw\n","y_test_vime = y_test_mw\n","\n","# Unlabeled data\n","x_unlab_vime = x_unlab\n","\n","# Labeled data\n","x_train_vime = x_train\n","y_train_vime = y_train"],"metadata":{"id":"GqZIlDoGodl6","executionInfo":{"status":"ok","timestamp":1661594737644,"user_tz":-330,"elapsed":4,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["mlp_parameters = dict()\n","mlp_parameters['hidden_dim'] = 100\n","mlp_parameters['epochs'] = 100\n","mlp_parameters['activation'] = 'relu'\n","mlp_parameters['batch_size'] = 128\n","mlp_parameters['num_layers'] = 4"],"metadata":{"id":"LQSHXGflodl7","executionInfo":{"status":"ok","timestamp":1661594741237,"user_tz":-330,"elapsed":3,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","MLP suggested by HEXR\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import backend\n","\n","from tensorflow.keras.layers import LeakyReLU\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","import math\n","\n","\"\"\"\n","Parameterized Activation functions.\n","\"\"\"\n","\n","\"\"\"\n","Initializing parameters. We observe that a initialization from Uniform distribution \n","yield a better result than normal distribution.\n","\"\"\"\n","\n","initializer0 = keras.initializers.RandomUniform(minval = -1, maxval =1)\n","initializer1 = keras.initializers.RandomUniform(minval = 0.5, maxval =3) \n","\n","def param_elliot_function( signal, k1, k2 ,  derivative=False ):\n","    \"\"\" A parameterized version of Elliot activation function \"\"\"\n","    s = 1 # steepness\n","    \n","    abs_signal = (1 + tf.math.abs(signal * s))\n","    if derivative:\n","        return 0.5 * s / abs_signal**2\n","    else:\n","        # Return the activation signal\n","        return (k1*(signal * s) / abs_signal + k2)\n","\n","class ParamElliotfn(keras.layers.Layer):\n","    def __init__(self, trainable = True):\n","        super(ParamElliotfn, self).__init__()\n","        self.k1 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","        self.k2 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","    def call(self, inputs):\n","        return param_elliot_function(inputs, self.k1, self.k2 )\n","\n","\n","def hexr_mlp(x_train, y_train, x_test, parameters):\n","\n","  print(\"HEXR MLP\")\n","\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  # K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  # Arelu = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","  \n","  print(\"Supervised MLP training sing Parameterized Elliot activation.\") \n","  Elliot = ParamElliotfn()\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = Elliot))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = Elliot))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # print(\"Balancing classes\") \n","  # from sklearn.utils.class_weight import compute_sample_weight\n","  # sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n","\n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid),epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","\n","  \n","  return y_test_hat"],"metadata":{"id":"2a6z--GTodl7","executionInfo":{"status":"ok","timestamp":1661594741238,"user_tz":-330,"elapsed":3,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["\"\"\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain (VIME) Codebase.\n","\n","Reference: Jinsung Yoon, Yao Zhang, James Jordon, Mihaela van der Schaar, \n","\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain,\" \n","Neural Information Processing Systems (NeurIPS), 2020.\n","Paper link: TBD\n","Last updated Date: October 11th 2020\n","Code author: Jinsung Yoon (jsyoon0823@gmail.com)\n","-----------------------------\n","\n","supervised_models.py\n","- Train supervised model and return predictions on the testing data\n","\n","(1) logit: logistic regression\n","(2) xgb_model: XGBoost model\n","(3) mlp: multi-layer perceptrons\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","  \n","#%% \n","def vime_mlp(x_train, y_train, x_test, parameters):\n","  print(\"VIME MLP\")\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  act_fn = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","\n","  # Build model\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = act_fn))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = act_fn))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  \n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam', \n","                metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', \n","                     verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid), \n","            epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","  \n","  return y_test_hat"],"metadata":{"id":"CzDCNDA4odl7","executionInfo":{"status":"ok","timestamp":1661594742374,"user_tz":-330,"elapsed":3,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Wheelchair scaled results\n","\"\"\"\n","\n","# results_HEXR_acc = []\n","# results_HEXR_auc = []\n","# results_VIME_acc = []\n","# results_VIME_auc = []\n","# hexrSup_test_acc = []\n","# hexrSup_test_auc = []\n","# vimeSup_test_acc = []\n","# vimeSup_test_auc = []\n","\n","\n","# for i in range(0,5):\n","\n","#   mlp_parameters = dict()\n","#   mlp_parameters['hidden_dim'] = 100\n","#   mlp_parameters['epochs'] = 100\n","#   mlp_parameters['activation'] = 'relu'\n","#   mlp_parameters['batch_size'] = 32\n","#   mlp_parameters['num_layers'] = 4\n","  \n","#   #supervised - HEXR\n","#   # y_test_hat = hexr_mlp(x_train, y_train, x_test, mlp_parameters)\n","#   # mlp_perf1 = perf_metric(metric1, y_test, y_test_hat)\n","#   # hexrSup_test_acc.append(mlp_perf1)\n","#   # hexrSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","#   # print(\"HEXR MLP performance : {}\".format(mlp_perf1))\n","\n","#   #supervised - VIME\n","#   y_test_hat = vime_mlp(x_train, y_train, x_test, mlp_parameters)\n","#   mlp_perf2 = perf_metric(metric1, y_test, y_test_hat)\n","#   vimeSup_test_acc.append(mlp_perf2)\n","#   vimeSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","#   print(\"VIME MLP performance : {}\".format(mlp_perf2))\n","\n","#   # Train HEXR-Self \n","#   vime_self_parameters = dict()\n","#   vime_self_parameters['batch_size'] = 128\n","#   vime_self_parameters['epochs'] = 10\n","#   hexr_self_encoder = hexr_self(x_unlab, p_m, alpha, vime_self_parameters)\n","    \n","#   # Save encoder\n","#   if not os.path.exists('save_model'):\n","#     os.makedirs('save_model')\n","\n","#   file_name = './save_model/wheelchair_HEXR_encoder_model_{}.h5'.format(i)\n","    \n","#   hexr_self_encoder.save(file_name)  \n","          \n","#   # Test HEXR-Self\n","#   x_train_hat = hexr_self_encoder.predict(x_train)\n","#   x_test_hat = hexr_self_encoder.predict(x_test)\n","        \n","#   y_test_hat1 = vime_mlp(x_train_hat, y_train, x_test_hat, mlp_parameters)\n","#   res = perf_metric(metric1, y_test, y_test_hat1)\n","#   results_HEXR_acc.append(perf_metric(metric1, y_test, y_test_hat1))\n","#   results_HEXR_auc.append(perf_metric(metric2, y_test, y_test_hat1))\n","        \n","#   print('HEXR-Self Performance: ' + str(res))\n","\n","#   #Train VIME self\n","#   vime_self_parameters = dict()\n","#   vime_self_parameters['batch_size'] = 128\n","#   vime_self_parameters['epochs'] = 10\n","#   vime_self_encoder = vime_self(x_unlab_vime, p_m, alpha, vime_self_parameters)\n","\n","#   file_name = './save_model/Wheelchair_VIME_encoder_model_{}.h5'.format(i)\n","    \n","#   vime_self_encoder.save(file_name)  \n","          \n","#   # Test VIME-Self\n","#   x_train_hat = vime_self_encoder.predict(x_train_vime)\n","#   x_test_hat = vime_self_encoder.predict(x_test_vime)\n","        \n","#   y_test_hat2 = vime_mlp(x_train_hat, y_train_vime, x_test_hat, mlp_parameters)\n","#   res2 = perf_metric(metric1, y_test_vime, y_test_hat2)\n","#   results_VIME_acc.append(res2)\n","#   results_VIME_auc.append(perf_metric(metric2, y_test_vime, y_test_hat2))\n","        \n","#   print('VIME-Self Performance: ' + str(res2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661006270067,"user_tz":-330,"elapsed":356973,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"884abd38-106e-4c38-c49e-25c4b90bfc42","id":"ujuIrVbVodl7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 21.\n","Epoch 71: early stopping\n","VIME MLP performance : 0.6442272891784292\n","Epoch 1/10\n","156/156 [==============================] - 2s 4ms/step - loss: 1.0310 - mask_loss: 0.6544 - feature_loss: 0.1883\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.9024 - mask_loss: 0.6156 - feature_loss: 0.1434\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8695 - mask_loss: 0.6145 - feature_loss: 0.1275\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8559 - mask_loss: 0.6137 - feature_loss: 0.1211\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8479 - mask_loss: 0.6131 - feature_loss: 0.1174\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8416 - mask_loss: 0.6129 - feature_loss: 0.1143\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8364 - mask_loss: 0.6127 - feature_loss: 0.1118\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8319 - mask_loss: 0.6126 - feature_loss: 0.1097\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8283 - mask_loss: 0.6124 - feature_loss: 0.1079\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8251 - mask_loss: 0.6123 - feature_loss: 0.1064\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 13.\n","Epoch 63: early stopping\n","HEXR-Self Performance: 0.5667752442996743\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.7587 - mask_loss: 0.6382 - feature_loss: 0.0603\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6197 - mask_loss: 0.6113 - feature_loss: 0.0042\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6139 - mask_loss: 0.6111 - feature_loss: 0.0014\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6137 - mask_loss: 0.6111 - feature_loss: 0.0013\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6136 - mask_loss: 0.6110 - feature_loss: 0.0013\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6135 - mask_loss: 0.6110 - feature_loss: 0.0012\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6133 - mask_loss: 0.6110 - feature_loss: 0.0012\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6132 - mask_loss: 0.6110 - feature_loss: 0.0011\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6131 - mask_loss: 0.6110 - feature_loss: 0.0011\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6130 - mask_loss: 0.6109 - feature_loss: 0.0011\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.45620702135360114\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 28.\n","Epoch 78: early stopping\n","VIME MLP performance : 0.6398841838581252\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.0521 - mask_loss: 0.6352 - feature_loss: 0.2084\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8998 - mask_loss: 0.6165 - feature_loss: 0.1416\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8657 - mask_loss: 0.6146 - feature_loss: 0.1256\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8522 - mask_loss: 0.6136 - feature_loss: 0.1193\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8445 - mask_loss: 0.6130 - feature_loss: 0.1158\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8390 - mask_loss: 0.6125 - feature_loss: 0.1132\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8348 - mask_loss: 0.6123 - feature_loss: 0.1113\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8313 - mask_loss: 0.6120 - feature_loss: 0.1096\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8283 - mask_loss: 0.6118 - feature_loss: 0.1082\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8256 - mask_loss: 0.6116 - feature_loss: 0.1070\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 25.\n","Epoch 75: early stopping\n","HEXR-Self Performance: 0.6154542164314152\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.7265 - mask_loss: 0.6254 - feature_loss: 0.0506\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6146 - mask_loss: 0.6106 - feature_loss: 0.0020\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6133 - mask_loss: 0.6106 - feature_loss: 0.0014\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6132 - mask_loss: 0.6106 - feature_loss: 0.0013\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6131 - mask_loss: 0.6105 - feature_loss: 0.0013\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6130 - mask_loss: 0.6105 - feature_loss: 0.0013\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6130 - mask_loss: 0.6105 - feature_loss: 0.0012\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6129 - mask_loss: 0.6105 - feature_loss: 0.0012\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6127 - mask_loss: 0.6105 - feature_loss: 0.0011\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6127 - mask_loss: 0.6105 - feature_loss: 0.0011\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.41512848353239235\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 10.\n","Epoch 60: early stopping\n","VIME MLP performance : 0.5826999638074557\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.0301 - mask_loss: 0.6292 - feature_loss: 0.2004\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.9248 - mask_loss: 0.6128 - feature_loss: 0.1560\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8830 - mask_loss: 0.6129 - feature_loss: 0.1350\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8638 - mask_loss: 0.6126 - feature_loss: 0.1256\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8529 - mask_loss: 0.6121 - feature_loss: 0.1204\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8454 - mask_loss: 0.6118 - feature_loss: 0.1168\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8397 - mask_loss: 0.6115 - feature_loss: 0.1141\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8352 - mask_loss: 0.6113 - feature_loss: 0.1120\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8315 - mask_loss: 0.6111 - feature_loss: 0.1102\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8284 - mask_loss: 0.6110 - feature_loss: 0.1087\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 30.\n","Epoch 80: early stopping\n","HEXR-Self Performance: 0.6103872602243938\n","Epoch 1/10\n","156/156 [==============================] - 2s 4ms/step - loss: 0.7313 - mask_loss: 0.6410 - feature_loss: 0.0451\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6144 - mask_loss: 0.6107 - feature_loss: 0.0018\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6132 - mask_loss: 0.6105 - feature_loss: 0.0013\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6131 - mask_loss: 0.6105 - feature_loss: 0.0013\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6129 - mask_loss: 0.6105 - feature_loss: 0.0012\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6128 - mask_loss: 0.6105 - feature_loss: 0.0012\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6127 - mask_loss: 0.6104 - feature_loss: 0.0011\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6126 - mask_loss: 0.6104 - feature_loss: 0.0011\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6125 - mask_loss: 0.6104 - feature_loss: 0.0010\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6123 - mask_loss: 0.6104 - feature_loss: 9.8294e-04\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.49022801302931596\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 17.\n","Epoch 67: early stopping\n","VIME MLP performance : 0.6205211726384365\n","Epoch 1/10\n","156/156 [==============================] - 2s 7ms/step - loss: 1.1455 - mask_loss: 0.6310 - feature_loss: 0.2573\n","Epoch 2/10\n","156/156 [==============================] - 1s 6ms/step - loss: 0.9312 - mask_loss: 0.6156 - feature_loss: 0.1578\n","Epoch 3/10\n","156/156 [==============================] - 1s 6ms/step - loss: 0.8833 - mask_loss: 0.6155 - feature_loss: 0.1339\n","Epoch 4/10\n","156/156 [==============================] - 1s 5ms/step - loss: 0.8646 - mask_loss: 0.6146 - feature_loss: 0.1250\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8544 - mask_loss: 0.6140 - feature_loss: 0.1202\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8473 - mask_loss: 0.6136 - feature_loss: 0.1169\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8418 - mask_loss: 0.6132 - feature_loss: 0.1143\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8375 - mask_loss: 0.6129 - feature_loss: 0.1123\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8338 - mask_loss: 0.6127 - feature_loss: 0.1106\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8308 - mask_loss: 0.6125 - feature_loss: 0.1092\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 14.\n","Epoch 64: early stopping\n","HEXR-Self Performance: 0.5624321389793703\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.7252 - mask_loss: 0.6458 - feature_loss: 0.0397\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6156 - mask_loss: 0.6117 - feature_loss: 0.0020\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6143 - mask_loss: 0.6116 - feature_loss: 0.0013\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6142 - mask_loss: 0.6116 - feature_loss: 0.0013\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6141 - mask_loss: 0.6116 - feature_loss: 0.0013\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6140 - mask_loss: 0.6116 - feature_loss: 0.0012\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6139 - mask_loss: 0.6115 - feature_loss: 0.0012\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6138 - mask_loss: 0.6115 - feature_loss: 0.0011\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6137 - mask_loss: 0.6115 - feature_loss: 0.0011\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6136 - mask_loss: 0.6115 - feature_loss: 0.0010\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.3858125226203402\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 29.\n","Epoch 79: early stopping\n","VIME MLP performance : 0.6536373507057546\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.0404 - mask_loss: 0.6545 - feature_loss: 0.1930\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.9120 - mask_loss: 0.6128 - feature_loss: 0.1496\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8722 - mask_loss: 0.6122 - feature_loss: 0.1300\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8543 - mask_loss: 0.6117 - feature_loss: 0.1213\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8446 - mask_loss: 0.6113 - feature_loss: 0.1167\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8382 - mask_loss: 0.6109 - feature_loss: 0.1137\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8333 - mask_loss: 0.6107 - feature_loss: 0.1113\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8295 - mask_loss: 0.6104 - feature_loss: 0.1095\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8262 - mask_loss: 0.6103 - feature_loss: 0.1079\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8233 - mask_loss: 0.6102 - feature_loss: 0.1066\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 13.\n","Epoch 63: early stopping\n","HEXR-Self Performance: 0.574737604053565\n","Epoch 1/10\n","156/156 [==============================] - 2s 4ms/step - loss: 0.7433 - mask_loss: 0.6369 - feature_loss: 0.0532\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6180 - mask_loss: 0.6123 - feature_loss: 0.0029\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6148 - mask_loss: 0.6121 - feature_loss: 0.0014\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6147 - mask_loss: 0.6121 - feature_loss: 0.0013\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6147 - mask_loss: 0.6121 - feature_loss: 0.0013\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6146 - mask_loss: 0.6120 - feature_loss: 0.0013\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6145 - mask_loss: 0.6120 - feature_loss: 0.0013\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6144 - mask_loss: 0.6120 - feature_loss: 0.0012\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6144 - mask_loss: 0.6120 - feature_loss: 0.0012\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.6143 - mask_loss: 0.6120 - feature_loss: 0.0011\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.37423090843286283\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Wheelchair Not Scaled results\n","\"\"\"\n","\n","# results_HEXR_acc = []\n","# results_HEXR_auc = []\n","# results_VIME_acc = []\n","# results_VIME_auc = []\n","# hexrSup_test_acc = []\n","# hexrSup_test_auc = []\n","# vimeSup_test_acc = []\n","# vimeSup_test_auc = []\n","\n","\n","# for i in range(0,5):\n","\n","#   mlp_parameters = dict()\n","#   mlp_parameters['hidden_dim'] = 100\n","#   mlp_parameters['epochs'] = 100\n","#   mlp_parameters['activation'] = 'relu'\n","#   mlp_parameters['batch_size'] = 32\n","#   mlp_parameters['num_layers'] = 4\n","  \n","#   #supervised - HEXR\n","#   # y_test_hat = hexr_mlp(x_train, y_train, x_test, mlp_parameters)\n","#   # mlp_perf1 = perf_metric(metric1, y_test, y_test_hat)\n","#   # hexrSup_test_acc.append(mlp_perf1)\n","#   # hexrSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","#   # print(\"HEXR MLP performance : {}\".format(mlp_perf1))\n","\n","#   #supervised - VIME\n","#   y_test_hat = vime_mlp(x_train, y_train, x_test, mlp_parameters)\n","#   mlp_perf2 = perf_metric(metric1, y_test, y_test_hat)\n","#   vimeSup_test_acc.append(mlp_perf2)\n","#   vimeSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","#   print(\"VIME MLP performance : {}\".format(mlp_perf2))\n","\n","#   # Train HEXR-Self \n","#   vime_self_parameters = dict()\n","#   vime_self_parameters['batch_size'] = 128\n","#   vime_self_parameters['epochs'] = 10\n","#   hexr_self_encoder = hexr_self(x_unlab, p_m, alpha, vime_self_parameters)\n","    \n","#   # Save encoder\n","#   if not os.path.exists('save_model'):\n","#     os.makedirs('save_model')\n","\n","#   file_name = './save_model/wheelchair_HEXR_encoder_model_{}.h5'.format(i)\n","    \n","#   hexr_self_encoder.save(file_name)  \n","          \n","#   # Test HEXR-Self\n","#   x_train_hat = hexr_self_encoder.predict(x_train)\n","#   x_test_hat = hexr_self_encoder.predict(x_test)\n","        \n","#   y_test_hat1 = vime_mlp(x_train_hat, y_train, x_test_hat, mlp_parameters)\n","#   res = perf_metric(metric1, y_test, y_test_hat1)\n","#   results_HEXR_acc.append(perf_metric(metric1, y_test, y_test_hat1))\n","#   results_HEXR_auc.append(perf_metric(metric2, y_test, y_test_hat1))\n","        \n","#   print('HEXR-Self Performance: ' + str(res))\n","\n","#   #Train VIME self\n","#   vime_self_parameters = dict()\n","#   vime_self_parameters['batch_size'] = 128\n","#   vime_self_parameters['epochs'] = 10\n","#   vime_self_encoder = vime_self(x_unlab_vime, p_m, alpha, vime_self_parameters)\n","\n","#   file_name = './save_model/Wheelchair_VIME_encoder_model_{}.h5'.format(i)\n","    \n","#   vime_self_encoder.save(file_name)  \n","          \n","#   # Test VIME-Self\n","#   x_train_hat = vime_self_encoder.predict(x_train_vime)\n","#   x_test_hat = vime_self_encoder.predict(x_test_vime)\n","        \n","#   y_test_hat2 = vime_mlp(x_train_hat, y_train_vime, x_test_hat, mlp_parameters)\n","#   res2 = perf_metric(metric1, y_test_vime, y_test_hat2)\n","#   results_VIME_acc.append(res2)\n","#   results_VIME_auc.append(perf_metric(metric2, y_test_vime, y_test_hat2))\n","        \n","#   print('VIME-Self Performance: ' + str(res2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n1bmszp7toUr","executionInfo":{"status":"ok","timestamp":1661007337106,"user_tz":-330,"elapsed":373193,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"0f87be56-74d0-41c7-d93f-6aca3610aa27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 19.\n","Epoch 69: early stopping\n","VIME MLP performance : 0.6373507057546145\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.0551 - mask_loss: 0.6346 - feature_loss: 0.2103\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.9390 - mask_loss: 0.6117 - feature_loss: 0.1637\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8925 - mask_loss: 0.6121 - feature_loss: 0.1402\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8698 - mask_loss: 0.6121 - feature_loss: 0.1288\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8555 - mask_loss: 0.6119 - feature_loss: 0.1218\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8462 - mask_loss: 0.6116 - feature_loss: 0.1173\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8398 - mask_loss: 0.6113 - feature_loss: 0.1143\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8350 - mask_loss: 0.6111 - feature_loss: 0.1119\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8311 - mask_loss: 0.6109 - feature_loss: 0.1101\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8279 - mask_loss: 0.6108 - feature_loss: 0.1086\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 18.\n","Epoch 68: early stopping\n","HEXR-Self Performance: 0.568765834238147\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.8348 - mask_loss: 0.6730 - feature_loss: 1.0809\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.3882 - mask_loss: 0.6327 - feature_loss: 0.8778\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.2272 - mask_loss: 0.6238 - feature_loss: 0.8017\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1700 - mask_loss: 0.6192 - feature_loss: 0.7754\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1427 - mask_loss: 0.6163 - feature_loss: 0.7632\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1273 - mask_loss: 0.6146 - feature_loss: 0.7564\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1178 - mask_loss: 0.6133 - feature_loss: 0.7522\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1115 - mask_loss: 0.6124 - feature_loss: 0.7495\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1069 - mask_loss: 0.6117 - feature_loss: 0.7476\n","Epoch 10/10\n","156/156 [==============================] - 1s 3ms/step - loss: 2.1034 - mask_loss: 0.6112 - feature_loss: 0.7461\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 17.\n","Epoch 67: early stopping\n","VIME-Self Performance: 0.5530220774520449\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 31.\n","Epoch 81: early stopping\n","VIME MLP performance : 0.6585233441910966\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.0315 - mask_loss: 0.6420 - feature_loss: 0.1947\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8896 - mask_loss: 0.6168 - feature_loss: 0.1364\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8571 - mask_loss: 0.6140 - feature_loss: 0.1216\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8446 - mask_loss: 0.6127 - feature_loss: 0.1160\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8370 - mask_loss: 0.6119 - feature_loss: 0.1125\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8316 - mask_loss: 0.6114 - feature_loss: 0.1101\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8277 - mask_loss: 0.6111 - feature_loss: 0.1083\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8244 - mask_loss: 0.6108 - feature_loss: 0.1068\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8218 - mask_loss: 0.6107 - feature_loss: 0.1055\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8193 - mask_loss: 0.6106 - feature_loss: 0.1044\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.6833152370611654\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.8163 - mask_loss: 0.6788 - feature_loss: 1.0688\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.3924 - mask_loss: 0.6357 - feature_loss: 0.8784\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.2242 - mask_loss: 0.6242 - feature_loss: 0.8000\n","Epoch 4/10\n","156/156 [==============================] - 1s 3ms/step - loss: 2.1626 - mask_loss: 0.6191 - feature_loss: 0.7717\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1366 - mask_loss: 0.6165 - feature_loss: 0.7601\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1225 - mask_loss: 0.6148 - feature_loss: 0.7538\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1138 - mask_loss: 0.6137 - feature_loss: 0.7501\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1081 - mask_loss: 0.6129 - feature_loss: 0.7476\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1040 - mask_loss: 0.6122 - feature_loss: 0.7459\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1009 - mask_loss: 0.6117 - feature_loss: 0.7446\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 34.\n","Epoch 84: early stopping\n","VIME-Self Performance: 0.6083966702859211\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 33.\n","Epoch 83: early stopping\n","VIME MLP performance : 0.6520086862106406\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.1015 - mask_loss: 0.6339 - feature_loss: 0.2338\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.9212 - mask_loss: 0.6150 - feature_loss: 0.1531\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8763 - mask_loss: 0.6143 - feature_loss: 0.1310\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8571 - mask_loss: 0.6134 - feature_loss: 0.1219\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8466 - mask_loss: 0.6128 - feature_loss: 0.1169\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8395 - mask_loss: 0.6122 - feature_loss: 0.1136\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8346 - mask_loss: 0.6119 - feature_loss: 0.1113\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8308 - mask_loss: 0.6117 - feature_loss: 0.1096\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8277 - mask_loss: 0.6114 - feature_loss: 0.1081\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8251 - mask_loss: 0.6113 - feature_loss: 0.1069\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 38.\n","Epoch 88: early stopping\n","HEXR-Self Performance: 0.6302931596091205\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.8339 - mask_loss: 0.6732 - feature_loss: 1.0803\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.3820 - mask_loss: 0.6327 - feature_loss: 0.8746\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.2191 - mask_loss: 0.6240 - feature_loss: 0.7976\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1579 - mask_loss: 0.6192 - feature_loss: 0.7693\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1341 - mask_loss: 0.6164 - feature_loss: 0.7588\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1222 - mask_loss: 0.6145 - feature_loss: 0.7538\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1149 - mask_loss: 0.6133 - feature_loss: 0.7508\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1097 - mask_loss: 0.6123 - feature_loss: 0.7487\n","Epoch 9/10\n","156/156 [==============================] - 1s 3ms/step - loss: 2.1058 - mask_loss: 0.6115 - feature_loss: 0.7471\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1025 - mask_loss: 0.6109 - feature_loss: 0.7458\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 10.\n","Epoch 60: early stopping\n","VIME-Self Performance: 0.5047050307636627\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 31.\n","Epoch 81: early stopping\n","VIME MLP performance : 0.6547231270358306\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.0832 - mask_loss: 0.6523 - feature_loss: 0.2154\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.9085 - mask_loss: 0.6154 - feature_loss: 0.1465\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8715 - mask_loss: 0.6143 - feature_loss: 0.1286\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8547 - mask_loss: 0.6135 - feature_loss: 0.1206\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8448 - mask_loss: 0.6129 - feature_loss: 0.1160\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8383 - mask_loss: 0.6125 - feature_loss: 0.1129\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8333 - mask_loss: 0.6122 - feature_loss: 0.1106\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8293 - mask_loss: 0.6119 - feature_loss: 0.1087\n","Epoch 9/10\n","156/156 [==============================] - 1s 5ms/step - loss: 0.8258 - mask_loss: 0.6116 - feature_loss: 0.1071\n","Epoch 10/10\n","156/156 [==============================] - 1s 5ms/step - loss: 0.8229 - mask_loss: 0.6115 - feature_loss: 0.1057\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 31.\n","Epoch 81: early stopping\n","HEXR-Self Performance: 0.6152732537097358\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.7844 - mask_loss: 0.6634 - feature_loss: 1.0605\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.3674 - mask_loss: 0.6314 - feature_loss: 0.8680\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.2223 - mask_loss: 0.6232 - feature_loss: 0.7995\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1735 - mask_loss: 0.6191 - feature_loss: 0.7772\n","Epoch 5/10\n","156/156 [==============================] - 1s 3ms/step - loss: 2.1450 - mask_loss: 0.6168 - feature_loss: 0.7641\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1247 - mask_loss: 0.6153 - feature_loss: 0.7547\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1150 - mask_loss: 0.6142 - feature_loss: 0.7504\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1087 - mask_loss: 0.6133 - feature_loss: 0.7477\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1043 - mask_loss: 0.6126 - feature_loss: 0.7458\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1007 - mask_loss: 0.6121 - feature_loss: 0.7443\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 48.\n","Epoch 98: early stopping\n","VIME-Self Performance: 0.6389793702497285\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 24.\n","Epoch 74: early stopping\n","VIME MLP performance : 0.6389793702497285\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.0135 - mask_loss: 0.6449 - feature_loss: 0.1843\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.9025 - mask_loss: 0.6143 - feature_loss: 0.1441\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8709 - mask_loss: 0.6138 - feature_loss: 0.1285\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8539 - mask_loss: 0.6134 - feature_loss: 0.1203\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8445 - mask_loss: 0.6130 - feature_loss: 0.1158\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8384 - mask_loss: 0.6126 - feature_loss: 0.1129\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8340 - mask_loss: 0.6124 - feature_loss: 0.1108\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8306 - mask_loss: 0.6122 - feature_loss: 0.1092\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8278 - mask_loss: 0.6120 - feature_loss: 0.1079\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8253 - mask_loss: 0.6118 - feature_loss: 0.1067\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 22.\n","Epoch 72: early stopping\n","HEXR-Self Performance: 0.5919290626131017\n","Epoch 1/10\n","156/156 [==============================] - 2s 4ms/step - loss: 2.8028 - mask_loss: 0.6809 - feature_loss: 1.0609\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.3662 - mask_loss: 0.6334 - feature_loss: 0.8664\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.2179 - mask_loss: 0.6244 - feature_loss: 0.7967\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1667 - mask_loss: 0.6198 - feature_loss: 0.7735\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1435 - mask_loss: 0.6172 - feature_loss: 0.7632\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1304 - mask_loss: 0.6156 - feature_loss: 0.7574\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1221 - mask_loss: 0.6145 - feature_loss: 0.7538\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1158 - mask_loss: 0.6136 - feature_loss: 0.7511\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1098 - mask_loss: 0.6131 - feature_loss: 0.7484\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1052 - mask_loss: 0.6125 - feature_loss: 0.7463\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 26.\n","Epoch 76: early stopping\n","VIME-Self Performance: 0.6007962359753891\n"]}]},{"cell_type":"code","source":["results_HEXR_acc = []\n","results_HEXR_f1_mic = []\n","results_HEXR_f1_mac = []\n","results_HEXR_f1_wei = []\n","\n","results_VIME_acc = []\n","results_VIME_f1_mic = []\n","results_VIME_f1_mac = []\n","results_VIME_f1_wei = []\n","\n","vimeSup_test_acc = []\n","vimeSup_test_f1_mic = []\n","vimeSup_test_f1_mac = []\n","vimeSup_test_f1_wei = []\n","\n","for i in range(0,5):\n","\n","  mlp_parameters = dict()\n","  mlp_parameters['hidden_dim'] = 100\n","  mlp_parameters['epochs'] = 100\n","  mlp_parameters['activation'] = 'relu'\n","  mlp_parameters['batch_size'] = 32\n","  mlp_parameters['num_layers'] = 4\n","  \n","  #supervised - HEXR\n","  # y_test_hat = hexr_mlp(x_train, y_train, x_test, mlp_parameters)\n","  # mlp_perf1 = perf_metric(metric1, y_test, y_test_hat)\n","  # hexrSup_test_acc.append(mlp_perf1)\n","  # hexrSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  # print(\"HEXR MLP performance : {}\".format(mlp_perf1))\n","\n","  #supervised - VIME\n","  y_test_hat = vime_mlp(x_train, y_train, x_test, mlp_parameters)\n","  mlp_perf2 = perf_metric(metric1, y_test, y_test_hat)\n","  vimeSup_test_acc.append(mlp_perf2)\n","  # vimeSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  vimeSup_test_f1_mic.append(f1_score(y_test.argmax(1),y_test_hat.argmax(1),average=\"micro\"))\n","  vimeSup_test_f1_mac.append(f1_score(y_test.argmax(1),y_test_hat.argmax(1),average=\"macro\"))\n","  vimeSup_test_f1_wei.append(f1_score(y_test.argmax(1),y_test_hat.argmax(1),average=\"weighted\"))\n","  print(\"VIME MLP performance : {}\".format(mlp_perf2))\n","\n","  # Train HEXR-Self \n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  hexr_self_encoder = hexr_self(x_unlab, p_m, alpha, vime_self_parameters)\n","    \n","  # Save encoder\n","  if not os.path.exists('save_model'):\n","    os.makedirs('save_model')\n","\n","  file_name = './save_model/wheelchair_HEXR_encoder_model_{}.h5'.format(i)\n","    \n","  hexr_self_encoder.save(file_name)  \n","          \n","  # Test HEXR-Self\n","  x_train_hat = hexr_self_encoder.predict(x_train)\n","  x_test_hat = hexr_self_encoder.predict(x_test)\n","        \n","  y_test_hat1 = vime_mlp(x_train_hat, y_train, x_test_hat, mlp_parameters)\n","  res = perf_metric(metric1, y_test, y_test_hat1)\n","  results_HEXR_acc.append(perf_metric(metric1, y_test, y_test_hat1))\n","  # results_HEXR_auc.append(perf_metric(metric2, y_test, y_test_hat1))\n","  results_HEXR_f1_mic.append(f1_score(y_test.argmax(1),y_test_hat1.argmax(1),average=\"micro\"))\n","  results_HEXR_f1_mac.append(f1_score(y_test.argmax(1),y_test_hat1.argmax(1),average=\"macro\"))\n","  results_HEXR_f1_wei.append(f1_score(y_test.argmax(1),y_test_hat1.argmax(1),average=\"weighted\"))\n","        \n","  print('HEXR-Self Performance: ' + str(res))\n","\n","  #Train VIME self\n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  vime_self_encoder = vime_self(x_unlab_vime, p_m, alpha, vime_self_parameters)\n","\n","  file_name = './save_model/Wheelchair_VIME_encoder_model_{}.h5'.format(i)\n","    \n","  vime_self_encoder.save(file_name)  \n","          \n","  # Test VIME-Self\n","  x_train_hat = vime_self_encoder.predict(x_train_vime)\n","  x_test_hat = vime_self_encoder.predict(x_test_vime)\n","        \n","  y_test_hat2 = vime_mlp(x_train_hat, y_train_vime, x_test_hat, mlp_parameters)\n","  res2 = perf_metric(metric1, y_test_vime, y_test_hat2)\n","  results_VIME_acc.append(res2)\n","  # results_VIME_auc.append(perf_metric(metric2, y_test_vime, y_test_hat2))\n","  results_VIME_f1_mic.append(f1_score(y_test.argmax(1),y_test_hat2.argmax(1),average=\"micro\"))\n","  results_VIME_f1_mac.append(f1_score(y_test.argmax(1),y_test_hat2.argmax(1),average=\"macro\"))\n","  results_VIME_f1_wei.append(f1_score(y_test.argmax(1),y_test_hat2.argmax(1),average=\"weighted\"))\n","        \n","  print('VIME-Self Performance: ' + str(res2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmxIYve-wN3E","executionInfo":{"status":"ok","timestamp":1661596845325,"user_tz":-330,"elapsed":372203,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"a66cf3de-5969-4330-daaf-e902b2ae4d30"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 25.\n","Epoch 75: early stopping\n","VIME MLP performance : 0.6409699601882012\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.0503 - mask_loss: 0.6462 - feature_loss: 0.2021\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8927 - mask_loss: 0.6172 - feature_loss: 0.1377\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8594 - mask_loss: 0.6153 - feature_loss: 0.1220\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8454 - mask_loss: 0.6141 - feature_loss: 0.1157\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8376 - mask_loss: 0.6133 - feature_loss: 0.1122\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8322 - mask_loss: 0.6127 - feature_loss: 0.1097\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8280 - mask_loss: 0.6123 - feature_loss: 0.1079\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8247 - mask_loss: 0.6120 - feature_loss: 0.1064\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8219 - mask_loss: 0.6117 - feature_loss: 0.1051\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8195 - mask_loss: 0.6115 - feature_loss: 0.1040\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 28.\n","Epoch 78: early stopping\n","HEXR-Self Performance: 0.6199782844733985\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.7773 - mask_loss: 0.6593 - feature_loss: 1.0590\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.3317 - mask_loss: 0.6322 - feature_loss: 0.8497\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1729 - mask_loss: 0.6234 - feature_loss: 0.7747\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1200 - mask_loss: 0.6188 - feature_loss: 0.7506\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0979 - mask_loss: 0.6162 - feature_loss: 0.7408\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0858 - mask_loss: 0.6146 - feature_loss: 0.7356\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0780 - mask_loss: 0.6135 - feature_loss: 0.7322\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0724 - mask_loss: 0.6127 - feature_loss: 0.7299\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0679 - mask_loss: 0.6120 - feature_loss: 0.7279\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0641 - mask_loss: 0.6115 - feature_loss: 0.7263\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.6800579080709374\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 13.\n","Epoch 63: early stopping\n","VIME MLP performance : 0.6317408613825551\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.0807 - mask_loss: 0.6359 - feature_loss: 0.2224\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8994 - mask_loss: 0.6159 - feature_loss: 0.1418\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8641 - mask_loss: 0.6145 - feature_loss: 0.1248\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8503 - mask_loss: 0.6134 - feature_loss: 0.1185\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8420 - mask_loss: 0.6128 - feature_loss: 0.1146\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8357 - mask_loss: 0.6124 - feature_loss: 0.1117\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8307 - mask_loss: 0.6120 - feature_loss: 0.1093\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8268 - mask_loss: 0.6118 - feature_loss: 0.1075\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8236 - mask_loss: 0.6116 - feature_loss: 0.1060\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8208 - mask_loss: 0.6114 - feature_loss: 0.1047\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.6585233441910966\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.7904 - mask_loss: 0.6779 - feature_loss: 1.0562\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.3410 - mask_loss: 0.6340 - feature_loss: 0.8535\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1794 - mask_loss: 0.6251 - feature_loss: 0.7771\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1308 - mask_loss: 0.6205 - feature_loss: 0.7552\n","Epoch 5/10\n","156/156 [==============================] - 1s 3ms/step - loss: 2.1094 - mask_loss: 0.6178 - feature_loss: 0.7458\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0972 - mask_loss: 0.6160 - feature_loss: 0.7406\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0891 - mask_loss: 0.6148 - feature_loss: 0.7372\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0835 - mask_loss: 0.6139 - feature_loss: 0.7348\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0791 - mask_loss: 0.6131 - feature_loss: 0.7330\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0756 - mask_loss: 0.6126 - feature_loss: 0.7315\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 46.\n","Epoch 96: early stopping\n","VIME-Self Performance: 0.6331885631559898\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 30.\n","Epoch 80: early stopping\n","VIME MLP performance : 0.6639522258414766\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.1217 - mask_loss: 0.6587 - feature_loss: 0.2315\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.9087 - mask_loss: 0.6162 - feature_loss: 0.1463\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8707 - mask_loss: 0.6156 - feature_loss: 0.1276\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8545 - mask_loss: 0.6145 - feature_loss: 0.1200\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8454 - mask_loss: 0.6137 - feature_loss: 0.1159\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8391 - mask_loss: 0.6131 - feature_loss: 0.1130\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8342 - mask_loss: 0.6126 - feature_loss: 0.1108\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8303 - mask_loss: 0.6123 - feature_loss: 0.1090\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8269 - mask_loss: 0.6120 - feature_loss: 0.1075\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8241 - mask_loss: 0.6118 - feature_loss: 0.1062\n","Proposed self supervised learning framework (param act function + log cosh loss)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 45.\n","Epoch 95: early stopping\n","HEXR-Self Performance: 0.6617806731813246\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.7696 - mask_loss: 0.6630 - feature_loss: 1.0533\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.3376 - mask_loss: 0.6305 - feature_loss: 0.8535\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1865 - mask_loss: 0.6221 - feature_loss: 0.7822\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1356 - mask_loss: 0.6183 - feature_loss: 0.7586\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1115 - mask_loss: 0.6162 - feature_loss: 0.7476\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0977 - mask_loss: 0.6149 - feature_loss: 0.7414\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0886 - mask_loss: 0.6137 - feature_loss: 0.7374\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0821 - mask_loss: 0.6129 - feature_loss: 0.7346\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0773 - mask_loss: 0.6122 - feature_loss: 0.7325\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0735 - mask_loss: 0.6116 - feature_loss: 0.7309\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 44.\n","Epoch 94: early stopping\n","VIME-Self Performance: 0.6197973217517192\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 17.\n","Epoch 67: early stopping\n","VIME MLP performance : 0.6250452406804198\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.0296 - mask_loss: 0.6524 - feature_loss: 0.1886\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8800 - mask_loss: 0.6178 - feature_loss: 0.1311\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8518 - mask_loss: 0.6140 - feature_loss: 0.1189\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8410 - mask_loss: 0.6126 - feature_loss: 0.1142\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8342 - mask_loss: 0.6118 - feature_loss: 0.1112\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8292 - mask_loss: 0.6114 - feature_loss: 0.1089\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8251 - mask_loss: 0.6111 - feature_loss: 0.1070\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8219 - mask_loss: 0.6108 - feature_loss: 0.1055\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8192 - mask_loss: 0.6106 - feature_loss: 0.1043\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8168 - mask_loss: 0.6105 - feature_loss: 0.1032\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 39.\n","Epoch 89: early stopping\n","HEXR-Self Performance: 0.6549040897575099\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.8022 - mask_loss: 0.6637 - feature_loss: 1.0692\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.3631 - mask_loss: 0.6322 - feature_loss: 0.8655\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.2011 - mask_loss: 0.6242 - feature_loss: 0.7885\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1415 - mask_loss: 0.6200 - feature_loss: 0.7607\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1134 - mask_loss: 0.6174 - feature_loss: 0.7480\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1004 - mask_loss: 0.6157 - feature_loss: 0.7423\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0924 - mask_loss: 0.6146 - feature_loss: 0.7389\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0866 - mask_loss: 0.6137 - feature_loss: 0.7364\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0822 - mask_loss: 0.6130 - feature_loss: 0.7346\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0789 - mask_loss: 0.6125 - feature_loss: 0.7332\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 33.\n","Epoch 83: early stopping\n","VIME-Self Performance: 0.6112920738327905\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 15.\n","Epoch 65: early stopping\n","VIME MLP performance : 0.6120159247195078\n","Epoch 1/10\n","156/156 [==============================] - 1s 4ms/step - loss: 1.1259 - mask_loss: 0.6460 - feature_loss: 0.2399\n","Epoch 2/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.9628 - mask_loss: 0.6126 - feature_loss: 0.1751\n","Epoch 3/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.9026 - mask_loss: 0.6138 - feature_loss: 0.1444\n","Epoch 4/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8763 - mask_loss: 0.6141 - feature_loss: 0.1311\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8628 - mask_loss: 0.6136 - feature_loss: 0.1246\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8540 - mask_loss: 0.6132 - feature_loss: 0.1204\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8475 - mask_loss: 0.6129 - feature_loss: 0.1173\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8424 - mask_loss: 0.6127 - feature_loss: 0.1148\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8380 - mask_loss: 0.6124 - feature_loss: 0.1128\n","Epoch 10/10\n","156/156 [==============================] - 1s 4ms/step - loss: 0.8343 - mask_loss: 0.6123 - feature_loss: 0.1110\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 49.\n","Epoch 99: early stopping\n","HEXR-Self Performance: 0.6514657980456026\n","Epoch 1/10\n","156/156 [==============================] - 1s 5ms/step - loss: 2.8190 - mask_loss: 0.6628 - feature_loss: 1.0781\n","Epoch 2/10\n","156/156 [==============================] - 1s 5ms/step - loss: 2.3701 - mask_loss: 0.6314 - feature_loss: 0.8694\n","Epoch 3/10\n","156/156 [==============================] - 1s 5ms/step - loss: 2.1863 - mask_loss: 0.6220 - feature_loss: 0.7822\n","Epoch 4/10\n","156/156 [==============================] - 1s 5ms/step - loss: 2.1318 - mask_loss: 0.6176 - feature_loss: 0.7571\n","Epoch 5/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.1089 - mask_loss: 0.6152 - feature_loss: 0.7468\n","Epoch 6/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0962 - mask_loss: 0.6137 - feature_loss: 0.7412\n","Epoch 7/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0872 - mask_loss: 0.6128 - feature_loss: 0.7372\n","Epoch 8/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0807 - mask_loss: 0.6120 - feature_loss: 0.7344\n","Epoch 9/10\n","156/156 [==============================] - 1s 4ms/step - loss: 2.0761 - mask_loss: 0.6113 - feature_loss: 0.7324\n","Epoch 10/10\n","156/156 [==============================] - 1s 3ms/step - loss: 2.0723 - mask_loss: 0.6108 - feature_loss: 0.7307\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 22.\n","Epoch 72: early stopping\n","VIME-Self Performance: 0.5971769815418024\n"]}]},{"cell_type":"code","source":["vimeSup_test_acc, vimeSup_test_f1_mic, vimeSup_test_f1_mac, vimeSup_test_f1_wei "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661596848399,"user_tz":-330,"elapsed":11,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"6b1ddb40-8fcb-47a6-f207-e3f5c0bc3f6e","id":"TEom42iO3jgA"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.6409699601882012,\n","  0.6317408613825551,\n","  0.6639522258414766,\n","  0.6250452406804198,\n","  0.6120159247195078],\n"," [0.6409699601882012,\n","  0.6317408613825551,\n","  0.6639522258414766,\n","  0.6250452406804198,\n","  0.6120159247195078],\n"," [0.6277151390773057,\n","  0.5996344959210832,\n","  0.6526474299845427,\n","  0.5943494132668649,\n","  0.5869793682422312],\n"," [0.6388904832617054,\n","  0.6260778374929318,\n","  0.6657357799435839,\n","  0.6192602169828794,\n","  0.6044063782737684])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["results_VIME_acc, results_VIME_f1_mic, results_VIME_f1_mac, results_VIME_f1_wei"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661596848400,"user_tz":-330,"elapsed":8,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"5af30566-5531-4f63-acbf-d14053efe66e","id":"6hWv2Vov3jgB"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.6800579080709374,\n","  0.6331885631559898,\n","  0.6197973217517192,\n","  0.6112920738327905,\n","  0.5971769815418024],\n"," [0.6800579080709374,\n","  0.6331885631559898,\n","  0.6197973217517192,\n","  0.6112920738327905,\n","  0.5971769815418024],\n"," [0.6179744242929867,\n","  0.5947296086292674,\n","  0.5538969427255159,\n","  0.5583678935922659,\n","  0.5619414182951014],\n"," [0.6770715938729363,\n","  0.6331013154382023,\n","  0.6197102676916542,\n","  0.6116687830488349,\n","  0.5922036273520355])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["results_HEXR_acc, results_HEXR_f1_mic, results_HEXR_f1_mac, results_HEXR_f1_wei "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661596848400,"user_tz":-330,"elapsed":5,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"88d5c509-b401-4916-daaa-ca3843373c9b","id":"0BirIsoN3jgB"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.6199782844733985,\n","  0.6585233441910966,\n","  0.6617806731813246,\n","  0.6549040897575099,\n","  0.6514657980456026],\n"," [0.6199782844733985,\n","  0.6585233441910966,\n","  0.6617806731813246,\n","  0.6549040897575099,\n","  0.6514657980456026],\n"," [0.5924165616521727,\n","  0.6179317769010513,\n","  0.62028747691979,\n","  0.6206521173503444,\n","  0.636171835903368],\n"," [0.6226149900536975,\n","  0.6617421132892208,\n","  0.6605057169437578,\n","  0.6493065639090537,\n","  0.6498938418550188])"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["run 1"],"metadata":{"id":"E6Y4GcoQ3lFP"}},{"cell_type":"code","source":["vimeSup_test_acc, vimeSup_test_f1_mic, vimeSup_test_f1_mac, vimeSup_test_f1_wei "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"op3nyXkI05bq","executionInfo":{"status":"ok","timestamp":1661596340122,"user_tz":-330,"elapsed":24,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"4d97bec5-2efd-46a3-ab29-c03fc196a51c"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.6554469779225479,\n","  0.67661961635903,\n","  0.6245023525153819,\n","  0.6769815418023887,\n","  0.6114730365544698],\n"," [0.6554469779225479,\n","  0.67661961635903,\n","  0.6245023525153819,\n","  0.6769815418023887,\n","  0.6114730365544698],\n"," [0.6329428506637226,\n","  0.6182678404552042,\n","  0.5774491036712645,\n","  0.6570032461990539,\n","  0.5902053882637301],\n"," [0.655170333494531,\n","  0.6742586020260256,\n","  0.6240530548592805,\n","  0.6720374118416572,\n","  0.6095703408310962])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["results_VIME_acc, results_VIME_f1_mic, results_VIME_f1_mac, results_VIME_f1_wei"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0BVU0uIp0091","executionInfo":{"status":"ok","timestamp":1661596340122,"user_tz":-330,"elapsed":6,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"57b8607c-b552-40d3-8f82-dde03ec89f7a"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.6232356134636265,\n","  0.5564603691639523,\n","  0.6500180962721679,\n","  0.5993485342019544,\n","  0.6503800217155266],\n"," [0.6554469779225479,\n","  0.67661961635903,\n","  0.6245023525153819,\n","  0.6769815418023887,\n","  0.6114730365544698],\n"," [0.6329428506637226,\n","  0.6182678404552042,\n","  0.5774491036712645,\n","  0.6570032461990539,\n","  0.5902053882637301],\n"," [0.655170333494531,\n","  0.6742586020260256,\n","  0.6240530548592805,\n","  0.6720374118416572,\n","  0.6095703408310962])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["results_HEXR_acc, results_HEXR_f1_mic, results_HEXR_f1_mac, results_HEXR_f1_wei "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OWGM9iFD01AM","executionInfo":{"status":"ok","timestamp":1661596340122,"user_tz":-330,"elapsed":4,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"5fa3250d-13e5-429e-e644-1f4293d243e3"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.6259500542888164,\n","  0.6114730365544698,\n","  0.6301121968874411,\n","  0.6315598986608758,\n","  0.5906623235613464],\n"," [0.6554469779225479,\n","  0.67661961635903,\n","  0.6245023525153819,\n","  0.6769815418023887,\n","  0.6114730365544698],\n"," [0.6329428506637226,\n","  0.6182678404552042,\n","  0.5774491036712645,\n","  0.6570032461990539,\n","  0.5902053882637301],\n"," [0.655170333494531,\n","  0.6742586020260256,\n","  0.6240530548592805,\n","  0.6720374118416572,\n","  0.6095703408310962])"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["# Income"],"metadata":{"id":"bKvh3aUqrTYV"}},{"cell_type":"code","source":["#Run this cell for UCI income\n","\n","df_mw = pd.read_csv('/content/drive/MyDrive/HEXR/Data/adult_income.csv')\n","\n","ohe = OneHotEncoder()\n","#Choose either class1 or class2 to select either valence or arousal\n","df_ohe = pd.DataFrame(ohe.fit_transform(df_mw[['income']]).toarray())\n","df_mw.drop('Unnamed: 0', axis=1, inplace=True)\n","df_mw = df_mw.join(df_ohe)\n","\n","df_mw.drop('income', axis=1, inplace=True)\n","X = df_mw.loc[:,:'marital_status']\n","y = df_mw.iloc[:,13:]\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","scaler = MinMaxScaler()\n","\n","\n","X[['age', 'fnlwgt', 'education.num', 'occupation', 'relationship',\n","       'capital.gain', 'capital.loss', 'hours.per.week', 'gender', 'ethnicity',\n","       'native_country', 'work', 'marital_status']] = scaler.fit_transform(X[['age', 'fnlwgt', 'education.num', 'occupation', 'relationship',\n","       'capital.gain', 'capital.loss', 'hours.per.week', 'gender', 'ethnicity',\n","       'native_country', 'work', 'marital_status']])\n","\n","# # tf.random.experimental.Generator.from_seed(1)\n","\n","from sklearn.model_selection import train_test_split\n","#50-50% split\n","X_L_mw, X_U_mw, y_L_mw, y_test_mw = train_test_split(X,y,test_size=0.2,random_state=7) #20-80 split\n","\n","#converting to numpy arrays\n","X_L_mw = X_L_mw.iloc[:, :].values\n","y_L_mw = y_L_mw.iloc[:, :].values\n","X_U_mw = X_U_mw.iloc[:,:].values\n","y_test_mw = y_test_mw.iloc[:,:].values\n","X_L_mw.shape, X_U_mw.shape, y_L_mw.shape, y_test_mw.shape\n","\n","\n","x_train = X_L_mw\n","y_train = y_L_mw\n","x_test = X_U_mw\n","y_test = y_test_mw"],"metadata":{"id":"1UZLTDu2qtbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Experimental parameters\n","label_no = 1000  \n","model_sets = ['logit','mlp']\n","\n","#reconstuction loss is log cosh\n","#recon_loss = log_cosh\n","\n","# Hyper-parameters\n","p_m = 0.3\n","alpha = 2.0\n","K = 3\n","beta = 1.0\n","label_data_rate = 0.1\n","\n","# Metric\n","metric1 = 'acc'\n","metric2 = 'auc'"],"metadata":{"id":"-Y1RTTIyzmGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Divide labeled and unlabeled data\n","idx = np.random.permutation(len(y_train))\n","\n","# Label data : Unlabeled data = label_data_rate:(1-label_data_rate)\n","label_idx = idx[:int(len(idx)*label_data_rate)]\n","unlab_idx = idx[int(len(idx)*label_data_rate):]\n","\n","# Unlabeled data\n","x_unlab = x_train[unlab_idx, :]\n","\n","# Labeled data\n","x_train = x_train[label_idx, :] \n","y_train = y_train[label_idx, :]"],"metadata":{"id":"Vi2r7c9izmGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape, x_unlab.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661008354250,"user_tz":-330,"elapsed":4,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"cae81796-e044-4498-b831-57169d8f5cde","id":"YVBASOzqzmGm"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2604, 13), (23444, 13))"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["len(x_train[0, :])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661008427019,"user_tz":-330,"elapsed":563,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"fb2727d7-deaf-4320-e4f4-c3c597ee3574","id":"BMO5uEDgzmGm"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["x_train_vime = X_L_mw\n","y_train_vime = y_L_mw\n","x_test_vime = X_U_mw\n","y_test_vime = y_test_mw\n","\n","# Unlabeled data\n","x_unlab_vime = x_unlab\n","\n","# Labeled data\n","x_train_vime = x_train\n","y_train_vime = y_train"],"metadata":{"id":"pxkHEt79zmGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlp_parameters = dict()\n","mlp_parameters['hidden_dim'] = 100\n","mlp_parameters['epochs'] = 100\n","mlp_parameters['activation'] = 'relu'\n","mlp_parameters['batch_size'] = 128\n","mlp_parameters['num_layers'] = 5"],"metadata":{"id":"EIesyTJkzmGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","MLP suggested by HEXR\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import backend\n","\n","from tensorflow.keras.layers import LeakyReLU\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","import math\n","\n","\"\"\"\n","Parameterized Activation functions.\n","\"\"\"\n","\n","\"\"\"\n","Initializing parameters. We observe that a initialization from Uniform distribution \n","yield a better result than normal distribution.\n","\"\"\"\n","\n","initializer0 = keras.initializers.RandomUniform(minval = -1, maxval =1)\n","initializer1 = keras.initializers.RandomUniform(minval = 0.5, maxval =3) \n","\n","def param_elliot_function( signal, k1, k2 ,  derivative=False ):\n","    \"\"\" A parameterized version of Elliot activation function \"\"\"\n","    s = 1 # steepness\n","    \n","    abs_signal = (1 + tf.math.abs(signal * s))\n","    if derivative:\n","        return 0.5 * s / abs_signal**2\n","    else:\n","        # Return the activation signal\n","        return (k1*(signal * s) / abs_signal + k2)\n","\n","class ParamElliotfn(keras.layers.Layer):\n","    def __init__(self, trainable = True):\n","        super(ParamElliotfn, self).__init__()\n","        self.k1 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","        self.k2 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","    def call(self, inputs):\n","        return param_elliot_function(inputs, self.k1, self.k2 )\n","\n","\n","def hexr_mlp(x_train, y_train, x_test, parameters):\n","\n","  print(\"HEXR MLP\")\n","\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  # K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  # Arelu = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","  \n","  print(\"Supervised MLP training sing Parameterized Elliot activation.\") \n","  Elliot = ParamElliotfn()\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = Elliot))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = Elliot))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # print(\"Balancing classes\") \n","  # from sklearn.utils.class_weight import compute_sample_weight\n","  # sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n","\n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid),epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","\n","  \n","  return y_test_hat"],"metadata":{"id":"tEukkx7TzmGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain (VIME) Codebase.\n","\n","Reference: Jinsung Yoon, Yao Zhang, James Jordon, Mihaela van der Schaar, \n","\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain,\" \n","Neural Information Processing Systems (NeurIPS), 2020.\n","Paper link: TBD\n","Last updated Date: October 11th 2020\n","Code author: Jinsung Yoon (jsyoon0823@gmail.com)\n","-----------------------------\n","\n","supervised_models.py\n","- Train supervised model and return predictions on the testing data\n","\n","(1) logit: logistic regression\n","(2) xgb_model: XGBoost model\n","(3) mlp: multi-layer perceptrons\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","  \n","#%% \n","def vime_mlp(x_train, y_train, x_test, parameters):\n","  print(\"VIME MLP\")\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  act_fn = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","\n","  # Build model\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = act_fn))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = act_fn))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  \n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam', \n","                metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', \n","                     verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid), \n","            epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","  \n","  return y_test_hat"],"metadata":{"id":"Vy0zAxgVzmGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_HEXR_acc = []\n","results_HEXR_auc = []\n","results_VIME_acc = []\n","results_VIME_auc = []\n","hexrSup_test_acc = []\n","hexrSup_test_auc = []\n","vimeSup_test_acc = []\n","vimeSup_test_auc = []\n","\n","\n","for i in range(0,5):\n","\n","  mlp_parameters = dict()\n","  mlp_parameters['hidden_dim'] = 100\n","  mlp_parameters['epochs'] = 100\n","  mlp_parameters['activation'] = 'relu'\n","  mlp_parameters['batch_size'] = 128\n","  mlp_parameters['num_layers'] = 5\n","  \n","  #supervised - HEXR\n","  # y_test_hat = hexr_mlp(x_train, y_train, x_test, mlp_parameters)\n","  # mlp_perf1 = perf_metric(metric1, y_test, y_test_hat)\n","  # hexrSup_test_acc.append(mlp_perf1)\n","  # hexrSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  # print(\"HEXR MLP performance : {}\".format(mlp_perf1))\n","\n","  #supervised - VIME\n","  y_test_hat = vime_mlp(x_train, y_train, x_test, mlp_parameters)\n","  mlp_perf2 = perf_metric(metric1, y_test, y_test_hat)\n","  vimeSup_test_acc.append(mlp_perf2)\n","  vimeSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  print(\"VIME MLP performance : {}\".format(mlp_perf2))\n","\n","  # Train HEXR-Self \n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  hexr_self_encoder = hexr_self(x_unlab, p_m, alpha, vime_self_parameters)\n","    \n","  # Save encoder\n","  if not os.path.exists('save_model'):\n","    os.makedirs('save_model')\n","\n","  file_name = './save_model/HEXR_encoder_model_arousal_{}.h5'.format(i)\n","    \n","  hexr_self_encoder.save(file_name)  \n","          \n","  # Test HEXR-Self\n","  x_train_hat = hexr_self_encoder.predict(x_train)\n","  x_test_hat = hexr_self_encoder.predict(x_test)\n","        \n","  y_test_hat1 = vime_mlp(x_train_hat, y_train, x_test_hat, mlp_parameters)\n","  res = perf_metric(metric1, y_test, y_test_hat1)\n","  results_HEXR_acc.append(perf_metric(metric1, y_test, y_test_hat1))\n","  results_HEXR_auc.append(perf_metric(metric2, y_test, y_test_hat1))\n","        \n","  print('HEXR-Self Performance: ' + str(res))\n","\n","  #Train VIME self\n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  vime_self_encoder = vime_self(x_unlab_vime, p_m, alpha, vime_self_parameters)\n","\n","  file_name = './save_model/VIME_encoder_model_arousal_{}.h5'.format(i)\n","    \n","  vime_self_encoder.save(file_name)  \n","          \n","  # Test VIME-Self\n","  x_train_hat = vime_self_encoder.predict(x_train_vime)\n","  x_test_hat = vime_self_encoder.predict(x_test_vime)\n","        \n","  y_test_hat2 = vime_mlp(x_train_hat, y_train_vime, x_test_hat, mlp_parameters)\n","  res2 = perf_metric(metric1, y_test_vime, y_test_hat2)\n","  results_VIME_acc.append(res2)\n","  results_VIME_auc.append(perf_metric(metric2, y_test_vime, y_test_hat2))\n","        \n","  print('VIME-Self Performance: ' + str(res2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1661004407997,"user_tz":-330,"elapsed":6231009,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"f5cad81a-19fa-4d8f-da77-b8b2a6dba8b0","id":"YjFkMQz_zmGn"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME MLP performance : 0.8521237831076304\n","Epoch 1/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 8.5617 - mask_loss: 0.6132 - feature_loss: 3.9743\n","Epoch 2/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 5.0845 - mask_loss: 0.6124 - feature_loss: 2.2360\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.7186 - mask_loss: 0.6117 - feature_loss: 2.0535\n","Epoch 4/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.6627 - mask_loss: 0.6112 - feature_loss: 2.0258\n","Epoch 5/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.6447 - mask_loss: 0.6110 - feature_loss: 2.0169\n","Epoch 6/10\n","8275/8275 [==============================] - 35s 4ms/step - loss: 4.6281 - mask_loss: 0.6110 - feature_loss: 2.0085\n","Epoch 7/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.6069 - mask_loss: 0.6111 - feature_loss: 1.9979\n","Epoch 8/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.5893 - mask_loss: 0.6110 - feature_loss: 1.9891\n","Epoch 9/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.5745 - mask_loss: 0.6110 - feature_loss: 1.9818\n","Epoch 10/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.5647 - mask_loss: 0.6110 - feature_loss: 1.9769\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8616005873715125\n","Epoch 1/10\n","8275/8275 [==============================] - 30s 3ms/step - loss: 0.6322 - mask_loss: 0.6123 - feature_loss: 0.0100\n","Epoch 2/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6266 - mask_loss: 0.6108 - feature_loss: 0.0079\n","Epoch 3/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6256 - mask_loss: 0.6099 - feature_loss: 0.0079\n","Epoch 4/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6253 - mask_loss: 0.6095 - feature_loss: 0.0079\n","Epoch 5/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 0.6251 - mask_loss: 0.6094 - feature_loss: 0.0079\n","Epoch 6/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6249 - mask_loss: 0.6093 - feature_loss: 0.0078\n","Epoch 7/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6249 - mask_loss: 0.6092 - feature_loss: 0.0078\n","Epoch 8/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6248 - mask_loss: 0.6092 - feature_loss: 0.0078\n","Epoch 9/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6248 - mask_loss: 0.6092 - feature_loss: 0.0078\n","Epoch 10/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6247 - mask_loss: 0.6091 - feature_loss: 0.0078\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8343292815576222\n","VIME MLP\n","VIME MLP performance : 0.850329036819492\n","Epoch 1/10\n","8275/8275 [==============================] - 34s 4ms/step - loss: 8.5267 - mask_loss: 0.6136 - feature_loss: 3.9565\n","Epoch 2/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 5.0170 - mask_loss: 0.6116 - feature_loss: 2.2027\n","Epoch 3/10\n","8275/8275 [==============================] - 34s 4ms/step - loss: 4.6934 - mask_loss: 0.6117 - feature_loss: 2.0409\n","Epoch 4/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.5748 - mask_loss: 0.6114 - feature_loss: 1.9817\n","Epoch 5/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.4853 - mask_loss: 0.6115 - feature_loss: 1.9369\n","Epoch 6/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.3980 - mask_loss: 0.6113 - feature_loss: 1.8933\n","Epoch 7/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.3527 - mask_loss: 0.6112 - feature_loss: 1.8707\n","Epoch 8/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.3287 - mask_loss: 0.6112 - feature_loss: 1.8587\n","Epoch 9/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.3127 - mask_loss: 0.6112 - feature_loss: 1.8507\n","Epoch 10/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.3008 - mask_loss: 0.6112 - feature_loss: 1.8448\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8649725349431664\n","Epoch 1/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6313 - mask_loss: 0.6117 - feature_loss: 0.0098\n","Epoch 2/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 0.6266 - mask_loss: 0.6106 - feature_loss: 0.0080\n","Epoch 3/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6261 - mask_loss: 0.6102 - feature_loss: 0.0079\n","Epoch 4/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 0.6255 - mask_loss: 0.6097 - feature_loss: 0.0079\n","Epoch 5/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6249 - mask_loss: 0.6092 - feature_loss: 0.0079\n","Epoch 6/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 0.6248 - mask_loss: 0.6090 - feature_loss: 0.0079\n","Epoch 7/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6247 - mask_loss: 0.6089 - feature_loss: 0.0079\n","Epoch 8/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6245 - mask_loss: 0.6088 - feature_loss: 0.0079\n","Epoch 9/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6242 - mask_loss: 0.6086 - feature_loss: 0.0078\n","Epoch 10/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6237 - mask_loss: 0.6081 - feature_loss: 0.0078\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8216912764453146\n","VIME MLP\n","VIME MLP performance : 0.8469536901071409\n","Epoch 1/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 8.7803 - mask_loss: 0.6154 - feature_loss: 4.0825\n","Epoch 2/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 5.1957 - mask_loss: 0.6118 - feature_loss: 2.2919\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.7463 - mask_loss: 0.6117 - feature_loss: 2.0673\n","Epoch 4/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.5541 - mask_loss: 0.6116 - feature_loss: 1.9712\n","Epoch 5/10\n","8275/8275 [==============================] - 34s 4ms/step - loss: 4.4573 - mask_loss: 0.6115 - feature_loss: 1.9229\n","Epoch 6/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.3884 - mask_loss: 0.6114 - feature_loss: 1.8885\n","Epoch 7/10\n","8275/8275 [==============================] - 34s 4ms/step - loss: 4.3526 - mask_loss: 0.6114 - feature_loss: 1.8706\n","Epoch 8/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.3309 - mask_loss: 0.6114 - feature_loss: 1.8598\n","Epoch 9/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.3169 - mask_loss: 0.6114 - feature_loss: 1.8528\n","Epoch 10/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.3048 - mask_loss: 0.6113 - feature_loss: 1.8467\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8633205525643117\n","Epoch 1/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6360 - mask_loss: 0.6131 - feature_loss: 0.0114\n","Epoch 2/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6265 - mask_loss: 0.6107 - feature_loss: 0.0079\n","Epoch 3/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6263 - mask_loss: 0.6105 - feature_loss: 0.0079\n","Epoch 4/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6263 - mask_loss: 0.6105 - feature_loss: 0.0079\n","Epoch 5/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6263 - mask_loss: 0.6105 - feature_loss: 0.0079\n","Epoch 6/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6263 - mask_loss: 0.6105 - feature_loss: 0.0079\n","Epoch 7/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6263 - mask_loss: 0.6105 - feature_loss: 0.0079\n","Epoch 8/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6263 - mask_loss: 0.6105 - feature_loss: 0.0079\n","Epoch 9/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 0.6262 - mask_loss: 0.6103 - feature_loss: 0.0080\n","Epoch 10/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6254 - mask_loss: 0.6093 - feature_loss: 0.0081\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8237375591450481\n","VIME MLP\n","VIME MLP performance : 0.8581946483928863\n","Epoch 1/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 8.6540 - mask_loss: 0.6148 - feature_loss: 4.0196\n","Epoch 2/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 5.1190 - mask_loss: 0.6117 - feature_loss: 2.2537\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.7255 - mask_loss: 0.6117 - feature_loss: 2.0569\n","Epoch 4/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.5551 - mask_loss: 0.6116 - feature_loss: 1.9718\n","Epoch 5/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.4665 - mask_loss: 0.6115 - feature_loss: 1.9275\n","Epoch 6/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.4269 - mask_loss: 0.6115 - feature_loss: 1.9077\n","Epoch 7/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4071 - mask_loss: 0.6114 - feature_loss: 1.8978\n","Epoch 8/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.3966 - mask_loss: 0.6114 - feature_loss: 1.8926\n","Epoch 9/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.3899 - mask_loss: 0.6114 - feature_loss: 1.8892\n","Epoch 10/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.3843 - mask_loss: 0.6114 - feature_loss: 1.8864\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8220107956708544\n","Epoch 1/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6324 - mask_loss: 0.6121 - feature_loss: 0.0102\n","Epoch 2/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6262 - mask_loss: 0.6103 - feature_loss: 0.0080\n","Epoch 3/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6251 - mask_loss: 0.6093 - feature_loss: 0.0079\n","Epoch 4/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6245 - mask_loss: 0.6087 - feature_loss: 0.0079\n","Epoch 5/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6242 - mask_loss: 0.6084 - feature_loss: 0.0079\n","Epoch 6/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6240 - mask_loss: 0.6082 - feature_loss: 0.0079\n","Epoch 7/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6238 - mask_loss: 0.6081 - feature_loss: 0.0079\n","Epoch 8/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6237 - mask_loss: 0.6079 - feature_loss: 0.0079\n","Epoch 9/10\n","8275/8275 [==============================] - 29s 3ms/step - loss: 0.6235 - mask_loss: 0.6077 - feature_loss: 0.0079\n","Epoch 10/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6233 - mask_loss: 0.6075 - feature_loss: 0.0079\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8200630880513406\n","VIME MLP\n","VIME MLP performance : 0.8486634578778485\n","Epoch 1/10\n","8275/8275 [==============================] - 34s 4ms/step - loss: 8.7144 - mask_loss: 0.6157 - feature_loss: 4.0494\n","Epoch 2/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 5.1041 - mask_loss: 0.6113 - feature_loss: 2.2464\n","Epoch 3/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.8153 - mask_loss: 0.6115 - feature_loss: 2.1019\n","Epoch 4/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.6617 - mask_loss: 0.6113 - feature_loss: 2.0252\n","Epoch 5/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.6011 - mask_loss: 0.6113 - feature_loss: 1.9949\n","Epoch 6/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 4.5647 - mask_loss: 0.6112 - feature_loss: 1.9767\n","Epoch 7/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.5372 - mask_loss: 0.6111 - feature_loss: 1.9630\n","Epoch 8/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.5145 - mask_loss: 0.6111 - feature_loss: 1.9517\n","Epoch 9/10\n","  55/8275 [..............................] - ETA: 31s - loss: 4.3871 - mask_loss: 0.6116 - feature_loss: 1.8877"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-fd5c4795296d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mvime_self_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mvime_self_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mhexr_self_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhexr_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_unlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvime_self_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m# Save encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/HEXR/Code/hexr_self.py\u001b[0m in \u001b[0;36mhexr_self\u001b[0;34m(x_unlab, p_m, alpha, parameters)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;31m# Fit model on unlabeled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_unlab\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;31m# Extract encoder part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# MNIST"],"metadata":{"id":"K1kvqfNJ147l"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0NinNSJgXXp"},"outputs":[],"source":["from data_loader_fashion import load_fmnist_data\n","from data_loader_m import load_mnist_data"]},{"cell_type":"code","source":["# Experimental parameters\n","label_no = 1000  \n","model_sets = ['logit','mlp']\n","\n","#reconstuction loss is log cosh\n","#recon_loss = log_cosh\n","\n","# Hyper-parameters\n","p_m = 0.3\n","alpha = 2.0\n","K = 3\n","beta = 1.0\n","label_data_rate = 0.1\n","\n","# Metric\n","metric1 = 'acc'\n","metric2 = 'auc'"],"metadata":{"id":"jJscV0pBkgBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ay0XgyRIOmpT","executionInfo":{"status":"ok","timestamp":1661508776559,"user_tz":-330,"elapsed":814,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6fbfa944-1e68-4343-9310-566aabebde4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}],"source":["# Load data\n","x_train, y_train, x_unlab, x_test, y_test = load_mnist_data(label_data_rate)"]},{"cell_type":"code","source":["# Unlabeled data\n","x_unlab_vime = x_unlab\n","\n","# Labeled data\n","x_train_vime = x_train\n","y_train_vime = y_train\n","x_test_vime = x_test\n","y_test_vime = y_test"],"metadata":{"id":"XGCBwlH82H7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","MLP suggested by HEXR\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import backend\n","\n","from tensorflow.keras.layers import LeakyReLU\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","import math\n","\n","\"\"\"\n","Parameterized Activation functions.\n","\"\"\"\n","\n","\"\"\"\n","Initializing parameters. We observe that a initialization from Uniform distribution \n","yield a better result than normal distribution.\n","\"\"\"\n","\n","initializer0 = keras.initializers.RandomUniform(minval = -1, maxval =1)\n","initializer1 = keras.initializers.RandomUniform(minval = 0.5, maxval =3) \n","\n","def param_elliot_function( signal, k1, k2 ,  derivative=False ):\n","    \"\"\" A parameterized version of Elliot activation function \"\"\"\n","    s = 1 # steepness\n","    \n","    abs_signal = (1 + tf.math.abs(signal * s))\n","    if derivative:\n","        return 0.5 * s / abs_signal**2\n","    else:\n","        # Return the activation signal\n","        return (k1*(signal * s) / abs_signal + k2)\n","\n","class ParamElliotfn(keras.layers.Layer):\n","    def __init__(self, trainable = True):\n","        super(ParamElliotfn, self).__init__()\n","        self.k1 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","        self.k2 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","    def call(self, inputs):\n","        return param_elliot_function(inputs, self.k1, self.k2 )\n","\n","\n","def hexr_mlp(x_train, y_train, x_test, parameters):\n","\n","  print(\"HEXR MLP\")\n","\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  # K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  # Arelu = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","  \n","  print(\"Supervised MLP training sing Parameterized Elliot activation.\") \n","  Elliot = ParamElliotfn()\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = Elliot))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = Elliot))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # print(\"Balancing classes\") \n","  # from sklearn.utils.class_weight import compute_sample_weight\n","  # sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n","\n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid),epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","\n","  \n","  return y_test_hat"],"metadata":{"id":"6cLIMkLZ2m9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain (VIME) Codebase.\n","\n","Reference: Jinsung Yoon, Yao Zhang, James Jordon, Mihaela van der Schaar, \n","\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain,\" \n","Neural Information Processing Systems (NeurIPS), 2020.\n","Paper link: TBD\n","Last updated Date: October 11th 2020\n","Code author: Jinsung Yoon (jsyoon0823@gmail.com)\n","-----------------------------\n","\n","supervised_models.py\n","- Train supervised model and return predictions on the testing data\n","\n","(1) logit: logistic regression\n","(2) xgb_model: XGBoost model\n","(3) mlp: multi-layer perceptrons\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","  \n","#%% \n","def vime_mlp(x_train, y_train, x_test, parameters):\n","  print(\"VIME MLP\")\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  act_fn = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","\n","  # Build model\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = act_fn))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = act_fn))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  \n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam', \n","                metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', \n","                     verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid), \n","            epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","  \n","  return y_test_hat"],"metadata":{"id":"lleSyREt2m9Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_HEXR_acc = []\n","results_HEXR_auc = []\n","results_VIME_acc = []\n","results_VIME_auc = []\n","hexrSup_test_acc = []\n","hexrSup_test_auc = []\n","vimeSup_test_acc = []\n","vimeSup_test_auc = []\n","\n","\n","for i in range(0,5):\n","\n","  mlp_parameters = dict()\n","  mlp_parameters['hidden_dim'] = 100\n","  mlp_parameters['epochs'] = 100\n","  mlp_parameters['activation'] = 'relu'\n","  mlp_parameters['batch_size'] = 128\n","  mlp_parameters['num_layers'] = 3\n","  \n","  #supervised - HEXR\n","  # y_test_hat = hexr_mlp(x_train, y_train, x_test, mlp_parameters)\n","  # mlp_perf1 = perf_metric(metric1, y_test, y_test_hat)\n","  # hexrSup_test_acc.append(mlp_perf1)\n","  # hexrSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  # print(\"HEXR MLP performance : {}\".format(mlp_perf1))\n","\n","  #supervised - VIME\n","  y_test_hat = vime_mlp(x_train, y_train, x_test, mlp_parameters)\n","  mlp_perf2 = perf_metric(metric1, y_test, y_test_hat)\n","  vimeSup_test_acc.append(mlp_perf2)\n","  vimeSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  print(\"VIME MLP performance : {}\".format(mlp_perf2))\n","\n","  # Train HEXR-Self \n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  hexr_self_encoder = hexr_self(x_unlab, p_m, alpha, vime_self_parameters)\n","    \n","  # Save encoder\n","  if not os.path.exists('save_model'):\n","    os.makedirs('save_model')\n","\n","  file_name = './save_model/HEXR_encoder_model_arousal_{}.h5'.format(i)\n","    \n","  hexr_self_encoder.save(file_name)  \n","          \n","  # Test HEXR-Self\n","  x_train_hat = hexr_self_encoder.predict(x_train)\n","  x_test_hat = hexr_self_encoder.predict(x_test)\n","        \n","  y_test_hat1 = vime_mlp(x_train_hat, y_train, x_test_hat, mlp_parameters)\n","  res = perf_metric(metric1, y_test, y_test_hat1)\n","  results_HEXR_acc.append(perf_metric(metric1, y_test, y_test_hat1))\n","  results_HEXR_auc.append(perf_metric(metric2, y_test, y_test_hat1))\n","        \n","  print('HEXR-Self Performance: ' + str(res))\n","\n","  #Train VIME self\n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  vime_self_encoder = vime_self(x_unlab_vime, p_m, alpha, vime_self_parameters)\n","\n","  file_name = './save_model/VIME_encoder_model_arousal_{}.h5'.format(i)\n","    \n","  vime_self_encoder.save(file_name)  \n","          \n","  # Test VIME-Self\n","  x_train_hat = vime_self_encoder.predict(x_train_vime)\n","  x_test_hat = vime_self_encoder.predict(x_test_vime)\n","        \n","  y_test_hat2 = vime_mlp(x_train_hat, y_train_vime, x_test_hat, mlp_parameters)\n","  res2 = perf_metric(metric1, y_test_vime, y_test_hat2)\n","  results_VIME_acc.append(res2)\n","  results_VIME_auc.append(perf_metric(metric2, y_test_vime, y_test_hat2))\n","        \n","  print('VIME-Self Performance: ' + str(res2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661509343625,"user_tz":-330,"elapsed":551514,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"ac168195-209a-482a-c17d-6030f8bc9beb","id":"_2Wsg-kI2G0_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 7.\n","Epoch 57: early stopping\n","VIME MLP performance : 0.9322\n","Epoch 1/10\n","422/422 [==============================] - 4s 8ms/step - loss: 0.2801 - mask_loss: 0.2262 - feature_loss: 0.0270\n","Epoch 2/10\n","422/422 [==============================] - 3s 8ms/step - loss: 0.2361 - mask_loss: 0.2172 - feature_loss: 0.0095\n","Epoch 3/10\n","422/422 [==============================] - 3s 7ms/step - loss: 0.2321 - mask_loss: 0.2154 - feature_loss: 0.0083\n","Epoch 4/10\n","422/422 [==============================] - 3s 8ms/step - loss: 0.2295 - mask_loss: 0.2137 - feature_loss: 0.0079\n","Epoch 5/10\n","422/422 [==============================] - 3s 8ms/step - loss: 0.2269 - mask_loss: 0.2115 - feature_loss: 0.0077\n","Epoch 6/10\n","422/422 [==============================] - 3s 6ms/step - loss: 0.2241 - mask_loss: 0.2087 - feature_loss: 0.0077\n","Epoch 7/10\n","422/422 [==============================] - 4s 9ms/step - loss: 0.2211 - mask_loss: 0.2058 - feature_loss: 0.0077\n","Epoch 8/10\n","422/422 [==============================] - 3s 8ms/step - loss: 0.2180 - mask_loss: 0.2027 - feature_loss: 0.0076\n","Epoch 9/10\n","422/422 [==============================] - 4s 9ms/step - loss: 0.2150 - mask_loss: 0.1997 - feature_loss: 0.0077\n","Epoch 10/10\n","422/422 [==============================] - 4s 9ms/step - loss: 0.2121 - mask_loss: 0.1968 - feature_loss: 0.0077\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 20.\n","Epoch 70: early stopping\n","HEXR-Self Performance: 0.9502\n","Epoch 1/10\n","422/422 [==============================] - 3s 5ms/step - loss: 0.2789 - mask_loss: 0.2267 - feature_loss: 0.0261\n","Epoch 2/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2439 - mask_loss: 0.2167 - feature_loss: 0.0136\n","Epoch 3/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2360 - mask_loss: 0.2126 - feature_loss: 0.0117\n","Epoch 4/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2299 - mask_loss: 0.2083 - feature_loss: 0.0108\n","Epoch 5/10\n","422/422 [==============================] - 3s 8ms/step - loss: 0.2240 - mask_loss: 0.2034 - feature_loss: 0.0103\n","Epoch 6/10\n","422/422 [==============================] - 4s 9ms/step - loss: 0.2184 - mask_loss: 0.1984 - feature_loss: 0.0100\n","Epoch 7/10\n","422/422 [==============================] - 3s 7ms/step - loss: 0.2133 - mask_loss: 0.1937 - feature_loss: 0.0098\n","Epoch 8/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2087 - mask_loss: 0.1893 - feature_loss: 0.0097\n","Epoch 9/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2045 - mask_loss: 0.1854 - feature_loss: 0.0095\n","Epoch 10/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2008 - mask_loss: 0.1819 - feature_loss: 0.0094\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 6.\n","Epoch 56: early stopping\n","VIME-Self Performance: 0.9462\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 11.\n","Epoch 61: early stopping\n","VIME MLP performance : 0.9409\n","Epoch 1/10\n","422/422 [==============================] - 4s 5ms/step - loss: 0.2855 - mask_loss: 0.2274 - feature_loss: 0.0290\n","Epoch 2/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2393 - mask_loss: 0.2185 - feature_loss: 0.0104\n","Epoch 3/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2336 - mask_loss: 0.2168 - feature_loss: 0.0084\n","Epoch 4/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2311 - mask_loss: 0.2156 - feature_loss: 0.0077\n","Epoch 5/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2292 - mask_loss: 0.2144 - feature_loss: 0.0074\n","Epoch 6/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2274 - mask_loss: 0.2129 - feature_loss: 0.0072\n","Epoch 7/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2254 - mask_loss: 0.2111 - feature_loss: 0.0071\n","Epoch 8/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2231 - mask_loss: 0.2089 - feature_loss: 0.0071\n","Epoch 9/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2205 - mask_loss: 0.2064 - feature_loss: 0.0071\n","Epoch 10/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2179 - mask_loss: 0.2037 - feature_loss: 0.0071\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 8.\n","Epoch 58: early stopping\n","HEXR-Self Performance: 0.9427\n","Epoch 1/10\n","422/422 [==============================] - 3s 5ms/step - loss: 0.2788 - mask_loss: 0.2266 - feature_loss: 0.0261\n","Epoch 2/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2439 - mask_loss: 0.2167 - feature_loss: 0.0136\n","Epoch 3/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2360 - mask_loss: 0.2126 - feature_loss: 0.0117\n","Epoch 4/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2299 - mask_loss: 0.2083 - feature_loss: 0.0108\n","Epoch 5/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2241 - mask_loss: 0.2035 - feature_loss: 0.0103\n","Epoch 6/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2185 - mask_loss: 0.1985 - feature_loss: 0.0100\n","Epoch 7/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2134 - mask_loss: 0.1938 - feature_loss: 0.0098\n","Epoch 8/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2089 - mask_loss: 0.1895 - feature_loss: 0.0097\n","Epoch 9/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2048 - mask_loss: 0.1857 - feature_loss: 0.0096\n","Epoch 10/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2011 - mask_loss: 0.1822 - feature_loss: 0.0095\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 11.\n","Epoch 61: early stopping\n","VIME-Self Performance: 0.9519\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 15.\n","Epoch 65: early stopping\n","VIME MLP performance : 0.9417\n","Epoch 1/10\n","422/422 [==============================] - 3s 5ms/step - loss: 0.2621 - mask_loss: 0.2248 - feature_loss: 0.0187\n","Epoch 2/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2345 - mask_loss: 0.2166 - feature_loss: 0.0089\n","Epoch 3/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2313 - mask_loss: 0.2149 - feature_loss: 0.0082\n","Epoch 4/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2290 - mask_loss: 0.2132 - feature_loss: 0.0079\n","Epoch 5/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2266 - mask_loss: 0.2111 - feature_loss: 0.0077\n","Epoch 6/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2241 - mask_loss: 0.2087 - feature_loss: 0.0077\n","Epoch 7/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2213 - mask_loss: 0.2061 - feature_loss: 0.0076\n","Epoch 8/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2185 - mask_loss: 0.2032 - feature_loss: 0.0076\n","Epoch 9/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2156 - mask_loss: 0.2004 - feature_loss: 0.0076\n","Epoch 10/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2128 - mask_loss: 0.1975 - feature_loss: 0.0076\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 11.\n","Epoch 61: early stopping\n","HEXR-Self Performance: 0.9483\n","Epoch 1/10\n","422/422 [==============================] - 3s 5ms/step - loss: 0.2790 - mask_loss: 0.2267 - feature_loss: 0.0262\n","Epoch 2/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2439 - mask_loss: 0.2167 - feature_loss: 0.0136\n","Epoch 3/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2359 - mask_loss: 0.2125 - feature_loss: 0.0117\n","Epoch 4/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2296 - mask_loss: 0.2080 - feature_loss: 0.0108\n","Epoch 5/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2236 - mask_loss: 0.2030 - feature_loss: 0.0103\n","Epoch 6/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2178 - mask_loss: 0.1979 - feature_loss: 0.0100\n","Epoch 7/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2126 - mask_loss: 0.1930 - feature_loss: 0.0098\n","Epoch 8/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2079 - mask_loss: 0.1887 - feature_loss: 0.0096\n","Epoch 9/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2037 - mask_loss: 0.1847 - feature_loss: 0.0095\n","Epoch 10/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2000 - mask_loss: 0.1812 - feature_loss: 0.0094\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 9.\n","Epoch 59: early stopping\n","VIME-Self Performance: 0.9488\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 8.\n","Epoch 58: early stopping\n","VIME MLP performance : 0.9384\n","Epoch 1/10\n","422/422 [==============================] - 3s 5ms/step - loss: 0.2624 - mask_loss: 0.2249 - feature_loss: 0.0187\n","Epoch 2/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2345 - mask_loss: 0.2167 - feature_loss: 0.0089\n","Epoch 3/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2314 - mask_loss: 0.2151 - feature_loss: 0.0082\n","Epoch 4/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2292 - mask_loss: 0.2134 - feature_loss: 0.0079\n","Epoch 5/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2268 - mask_loss: 0.2114 - feature_loss: 0.0077\n","Epoch 6/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2242 - mask_loss: 0.2090 - feature_loss: 0.0076\n","Epoch 7/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2215 - mask_loss: 0.2063 - feature_loss: 0.0076\n","Epoch 8/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2186 - mask_loss: 0.2034 - feature_loss: 0.0076\n","Epoch 9/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2157 - mask_loss: 0.2006 - feature_loss: 0.0076\n","Epoch 10/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2129 - mask_loss: 0.1977 - feature_loss: 0.0076\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 14.\n","Epoch 64: early stopping\n","HEXR-Self Performance: 0.9452\n","Epoch 1/10\n","422/422 [==============================] - 3s 5ms/step - loss: 0.2790 - mask_loss: 0.2266 - feature_loss: 0.0262\n","Epoch 2/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2441 - mask_loss: 0.2167 - feature_loss: 0.0137\n","Epoch 3/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2361 - mask_loss: 0.2127 - feature_loss: 0.0117\n","Epoch 4/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2300 - mask_loss: 0.2084 - feature_loss: 0.0108\n","Epoch 5/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2242 - mask_loss: 0.2035 - feature_loss: 0.0103\n","Epoch 6/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2185 - mask_loss: 0.1985 - feature_loss: 0.0100\n","Epoch 7/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2133 - mask_loss: 0.1937 - feature_loss: 0.0098\n","Epoch 8/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2086 - mask_loss: 0.1893 - feature_loss: 0.0096\n","Epoch 9/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2044 - mask_loss: 0.1854 - feature_loss: 0.0095\n","Epoch 10/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2006 - mask_loss: 0.1818 - feature_loss: 0.0094\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 7.\n","Epoch 57: early stopping\n","VIME-Self Performance: 0.9483\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 8.\n","Epoch 58: early stopping\n","VIME MLP performance : 0.9361\n","Epoch 1/10\n","422/422 [==============================] - 3s 5ms/step - loss: 0.2581 - mask_loss: 0.2275 - feature_loss: 0.0153\n","Epoch 2/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2355 - mask_loss: 0.2174 - feature_loss: 0.0091\n","Epoch 3/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2328 - mask_loss: 0.2160 - feature_loss: 0.0084\n","Epoch 4/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2311 - mask_loss: 0.2148 - feature_loss: 0.0081\n","Epoch 5/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2294 - mask_loss: 0.2136 - feature_loss: 0.0079\n","Epoch 6/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2277 - mask_loss: 0.2122 - feature_loss: 0.0078\n","Epoch 7/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2258 - mask_loss: 0.2104 - feature_loss: 0.0077\n","Epoch 8/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2237 - mask_loss: 0.2085 - feature_loss: 0.0076\n","Epoch 9/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2215 - mask_loss: 0.2064 - feature_loss: 0.0076\n","Epoch 10/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2192 - mask_loss: 0.2041 - feature_loss: 0.0076\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 7.\n","Epoch 57: early stopping\n","HEXR-Self Performance: 0.9343\n","Epoch 1/10\n","422/422 [==============================] - 3s 5ms/step - loss: 0.2791 - mask_loss: 0.2266 - feature_loss: 0.0262\n","Epoch 2/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2439 - mask_loss: 0.2166 - feature_loss: 0.0136\n","Epoch 3/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2359 - mask_loss: 0.2125 - feature_loss: 0.0117\n","Epoch 4/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2297 - mask_loss: 0.2081 - feature_loss: 0.0108\n","Epoch 5/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2236 - mask_loss: 0.2031 - feature_loss: 0.0103\n","Epoch 6/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2180 - mask_loss: 0.1980 - feature_loss: 0.0100\n","Epoch 7/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2128 - mask_loss: 0.1932 - feature_loss: 0.0098\n","Epoch 8/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2081 - mask_loss: 0.1888 - feature_loss: 0.0096\n","Epoch 9/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2039 - mask_loss: 0.1849 - feature_loss: 0.0095\n","Epoch 10/10\n","422/422 [==============================] - 2s 5ms/step - loss: 0.2003 - mask_loss: 0.1814 - feature_loss: 0.0094\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 7.\n","Epoch 57: early stopping\n","VIME-Self Performance: 0.9471\n"]}]},{"cell_type":"code","source":["results_HEXR_acc, results_VIME_acc, vimeSup_test_acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ItBVj2epDaI","executionInfo":{"status":"ok","timestamp":1661509345766,"user_tz":-330,"elapsed":10,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"12af188a-296b-414f-dd93-74215a18eddf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.9502, 0.9427, 0.9483, 0.9452, 0.9343],\n"," [0.9462, 0.9519, 0.9488, 0.9483, 0.9471],\n"," [0.9322, 0.9409, 0.9417, 0.9384, 0.9361])"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["results_HEXR_auc, results_VIME_auc, vimeSup_test_auc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvso1ZDHpGzX","executionInfo":{"status":"ok","timestamp":1661509345767,"user_tz":-330,"elapsed":6,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"0f1ef57f-84f4-4867-87a4-db4b513fa2bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.9990916115695294,\n","  0.9992334354524922,\n","  0.999527121208733,\n","  0.9996340605907009,\n","  0.9986694196600501],\n"," [0.9993696937170629,\n","  0.9991768847941839,\n","  0.9994725582712792,\n","  0.9996069282010381,\n","  0.9995908276621173],\n"," [0.9993445490482544,\n","  0.9991974577050272,\n","  0.9992230993040492,\n","  0.9989202700318781,\n","  0.9990983698204343])"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["# FMNIST"],"metadata":{"id":"dyCFnB2AHz0U"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWO1MJrOH5c7"},"outputs":[],"source":["from data_loader_fashion import load_fmnist_data\n","from data_loader_m import load_mnist_data"]},{"cell_type":"code","source":["# Experimental parameters\n","label_no = 1000  \n","model_sets = ['logit','mlp']\n","\n","#reconstuction loss is log cosh\n","#recon_loss = log_cosh\n","\n","# Hyper-parameters\n","p_m = 0.3\n","alpha = 2.0\n","K = 3\n","beta = 1.0\n","label_data_rate = 0.1\n","\n","# Metric\n","metric1 = 'acc'\n","metric2 = 'auc'"],"metadata":{"id":"nZkB06iQH5c8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"ok","timestamp":1661507358150,"user_tz":-330,"elapsed":1386,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8f674626-2cce-4a34-c9ac-9f42814fd8d2","id":"KXJxrJpZH5c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n"]}],"source":["# Load data\n","x_train, y_train, x_unlab, x_test, y_test = load_fmnist_data(label_data_rate)"]},{"cell_type":"code","source":["# Unlabeled data\n","x_unlab_vime = x_unlab\n","\n","# Labeled data\n","x_train_vime = x_train\n","y_train_vime = y_train\n","x_test_vime = x_test\n","y_test_vime = y_test"],"metadata":{"id":"DrUnmuDyH5c8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","MLP suggested by HEXR\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import backend\n","\n","from tensorflow.keras.layers import LeakyReLU\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","import math\n","\n","\"\"\"\n","Parameterized Activation functions.\n","\"\"\"\n","\n","\"\"\"\n","Initializing parameters. We observe that a initialization from Uniform distribution \n","yield a better result than normal distribution.\n","\"\"\"\n","\n","initializer0 = keras.initializers.RandomUniform(minval = -1, maxval =1)\n","initializer1 = keras.initializers.RandomUniform(minval = 0.5, maxval =3) \n","\n","def param_elliot_function( signal, k1, k2 ,  derivative=False ):\n","    \"\"\" A parameterized version of Elliot activation function \"\"\"\n","    s = 1 # steepness\n","    \n","    abs_signal = (1 + tf.math.abs(signal * s))\n","    if derivative:\n","        return 0.5 * s / abs_signal**2\n","    else:\n","        # Return the activation signal\n","        return (k1*(signal * s) / abs_signal + k2)\n","\n","class ParamElliotfn(keras.layers.Layer):\n","    def __init__(self, trainable = True):\n","        super(ParamElliotfn, self).__init__()\n","        self.k1 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","        self.k2 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","    def call(self, inputs):\n","        return param_elliot_function(inputs, self.k1, self.k2 )\n","\n","\n","def hexr_mlp(x_train, y_train, x_test, parameters):\n","\n","  print(\"HEXR MLP\")\n","\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  # K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  # Arelu = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","  \n","  print(\"Supervised MLP training sing Parameterized Elliot activation.\") \n","  Elliot = ParamElliotfn()\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = Elliot))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = Elliot))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # print(\"Balancing classes\") \n","  # from sklearn.utils.class_weight import compute_sample_weight\n","  # sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n","\n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid),epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","\n","  \n","  return y_test_hat"],"metadata":{"id":"1yjteFD3H5c8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain (VIME) Codebase.\n","\n","Reference: Jinsung Yoon, Yao Zhang, James Jordon, Mihaela van der Schaar, \n","\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain,\" \n","Neural Information Processing Systems (NeurIPS), 2020.\n","Paper link: TBD\n","Last updated Date: October 11th 2020\n","Code author: Jinsung Yoon (jsyoon0823@gmail.com)\n","-----------------------------\n","\n","supervised_models.py\n","- Train supervised model and return predictions on the testing data\n","\n","(1) logit: logistic regression\n","(2) xgb_model: XGBoost model\n","(3) mlp: multi-layer perceptrons\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","  \n","#%% \n","def vime_mlp(x_train, y_train, x_test, parameters):\n","  print(\"VIME MLP\")\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  act_fn = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","\n","  # Build model\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = act_fn))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = act_fn))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  \n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam', \n","                metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', \n","                     verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid), \n","            epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","  \n","  return y_test_hat"],"metadata":{"id":"teWJEumdH5c9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_HEXR_acc = []\n","results_HEXR_auc = []\n","results_VIME_acc = []\n","results_VIME_auc = []\n","hexrSup_test_acc = []\n","hexrSup_test_auc = []\n","vimeSup_test_acc = []\n","vimeSup_test_auc = []\n","\n","\n","for i in range(0,5):\n","\n","  mlp_parameters = dict()\n","  mlp_parameters['hidden_dim'] = 100\n","  mlp_parameters['epochs'] = 100\n","  mlp_parameters['activation'] = 'relu'\n","  mlp_parameters['batch_size'] = 128\n","  mlp_parameters['num_layers'] = 3\n","  \n","  #supervised - HEXR\n","  # y_test_hat = hexr_mlp(x_train, y_train, x_test, mlp_parameters)\n","  # mlp_perf1 = perf_metric(metric1, y_test, y_test_hat)\n","  # hexrSup_test_acc.append(mlp_perf1)\n","  # hexrSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  # print(\"HEXR MLP performance : {}\".format(mlp_perf1))\n","\n","  #supervised - VIME\n","  y_test_hat = vime_mlp(x_train, y_train, x_test, mlp_parameters)\n","  mlp_perf2 = perf_metric(metric1, y_test, y_test_hat)\n","  vimeSup_test_acc.append(mlp_perf2)\n","  vimeSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  print(\"VIME MLP performance : {}\".format(mlp_perf2))\n","\n","  # Train HEXR-Self \n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  hexr_self_encoder = hexr_self(x_unlab, p_m, alpha, vime_self_parameters)\n","    \n","  # Save encoder\n","  if not os.path.exists('save_model'):\n","    os.makedirs('save_model')\n","\n","  file_name = './save_model/HEXR_encoder_model_arousal_{}.h5'.format(i)\n","    \n","  hexr_self_encoder.save(file_name)  \n","          \n","  # Test HEXR-Self\n","  x_train_hat = hexr_self_encoder.predict(x_train)\n","  x_test_hat = hexr_self_encoder.predict(x_test)\n","        \n","  y_test_hat1 = vime_mlp(x_train_hat, y_train, x_test_hat, mlp_parameters)\n","  res = perf_metric(metric1, y_test, y_test_hat1)\n","  results_HEXR_acc.append(perf_metric(metric1, y_test, y_test_hat1))\n","  results_HEXR_auc.append(perf_metric(metric2, y_test, y_test_hat1))\n","        \n","  print('HEXR-Self Performance: ' + str(res))\n","\n","  #Train VIME self\n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  vime_self_encoder = vime_self(x_unlab_vime, p_m, alpha, vime_self_parameters)\n","\n","  file_name = './save_model/VIME_encoder_model_arousal_{}.h5'.format(i)\n","    \n","  vime_self_encoder.save(file_name)  \n","          \n","  # Test VIME-Self\n","  x_train_hat = vime_self_encoder.predict(x_train_vime)\n","  x_test_hat = vime_self_encoder.predict(x_test_vime)\n","        \n","  y_test_hat2 = vime_mlp(x_train_hat, y_train_vime, x_test_hat, mlp_parameters)\n","  res2 = perf_metric(metric1, y_test_vime, y_test_hat2)\n","  results_VIME_acc.append(res2)\n","  results_VIME_auc.append(perf_metric(metric2, y_test_vime, y_test_hat2))\n","        \n","  print('VIME-Self Performance: ' + str(res2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"59157af4-0b03-4ff6-b7a7-3e5fab1517e9","id":"zOJoERf8H5c-","executionInfo":{"status":"ok","timestamp":1661507865895,"user_tz":-330,"elapsed":498604,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 17.\n","Epoch 67: early stopping\n","VIME MLP performance : 0.8503571428571428\n","Epoch 1/10\n","394/394 [==============================] - 3s 5ms/step - loss: 0.5068 - mask_loss: 0.4602 - feature_loss: 0.0233\n","Epoch 2/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4798 - mask_loss: 0.4553 - feature_loss: 0.0122\n","Epoch 3/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4738 - mask_loss: 0.4540 - feature_loss: 0.0099\n","Epoch 4/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4705 - mask_loss: 0.4527 - feature_loss: 0.0089\n","Epoch 5/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4679 - mask_loss: 0.4511 - feature_loss: 0.0084\n","Epoch 6/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4652 - mask_loss: 0.4488 - feature_loss: 0.0082\n","Epoch 7/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4620 - mask_loss: 0.4456 - feature_loss: 0.0082\n","Epoch 8/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4581 - mask_loss: 0.4415 - feature_loss: 0.0083\n","Epoch 9/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4539 - mask_loss: 0.4371 - feature_loss: 0.0084\n","Epoch 10/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4497 - mask_loss: 0.4327 - feature_loss: 0.0085\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 39.\n","Epoch 89: early stopping\n","HEXR-Self Performance: 0.8582142857142857\n","Epoch 1/10\n","394/394 [==============================] - 3s 5ms/step - loss: 0.5336 - mask_loss: 0.4662 - feature_loss: 0.0337\n","Epoch 2/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4962 - mask_loss: 0.4558 - feature_loss: 0.0202\n","Epoch 3/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4834 - mask_loss: 0.4494 - feature_loss: 0.0170\n","Epoch 4/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4730 - mask_loss: 0.4420 - feature_loss: 0.0155\n","Epoch 5/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4633 - mask_loss: 0.4342 - feature_loss: 0.0146\n","Epoch 6/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4548 - mask_loss: 0.4268 - feature_loss: 0.0140\n","Epoch 7/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4475 - mask_loss: 0.4204 - feature_loss: 0.0136\n","Epoch 8/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4417 - mask_loss: 0.4152 - feature_loss: 0.0133\n","Epoch 9/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4369 - mask_loss: 0.4109 - feature_loss: 0.0130\n","Epoch 10/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4330 - mask_loss: 0.4073 - feature_loss: 0.0129\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 9.\n","Epoch 59: early stopping\n","VIME-Self Performance: 0.8522142857142857\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 19.\n","Epoch 69: early stopping\n","VIME MLP performance : 0.8490714285714286\n","Epoch 1/10\n","394/394 [==============================] - 3s 5ms/step - loss: 0.4962 - mask_loss: 0.4608 - feature_loss: 0.0177\n","Epoch 2/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4780 - mask_loss: 0.4552 - feature_loss: 0.0114\n","Epoch 3/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4738 - mask_loss: 0.4538 - feature_loss: 0.0100\n","Epoch 4/10\n","394/394 [==============================] - 2s 6ms/step - loss: 0.4710 - mask_loss: 0.4525 - feature_loss: 0.0092\n","Epoch 5/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4688 - mask_loss: 0.4512 - feature_loss: 0.0088\n","Epoch 6/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4666 - mask_loss: 0.4496 - feature_loss: 0.0085\n","Epoch 7/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4643 - mask_loss: 0.4476 - feature_loss: 0.0084\n","Epoch 8/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4618 - mask_loss: 0.4453 - feature_loss: 0.0082\n","Epoch 9/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4589 - mask_loss: 0.4424 - feature_loss: 0.0082\n","Epoch 10/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4557 - mask_loss: 0.4393 - feature_loss: 0.0082\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 23.\n","Epoch 73: early stopping\n","HEXR-Self Performance: 0.8527142857142858\n","Epoch 1/10\n","394/394 [==============================] - 3s 5ms/step - loss: 0.5335 - mask_loss: 0.4659 - feature_loss: 0.0338\n","Epoch 2/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4963 - mask_loss: 0.4557 - feature_loss: 0.0203\n","Epoch 3/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4832 - mask_loss: 0.4493 - feature_loss: 0.0170\n","Epoch 4/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4729 - mask_loss: 0.4420 - feature_loss: 0.0154\n","Epoch 5/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4631 - mask_loss: 0.4341 - feature_loss: 0.0145\n","Epoch 6/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4545 - mask_loss: 0.4266 - feature_loss: 0.0139\n","Epoch 7/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4472 - mask_loss: 0.4202 - feature_loss: 0.0135\n","Epoch 8/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4414 - mask_loss: 0.4148 - feature_loss: 0.0133\n","Epoch 9/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4366 - mask_loss: 0.4105 - feature_loss: 0.0130\n","Epoch 10/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4326 - mask_loss: 0.4068 - feature_loss: 0.0129\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 10.\n","Epoch 60: early stopping\n","VIME-Self Performance: 0.8517142857142858\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 21.\n","Epoch 71: early stopping\n","VIME MLP performance : 0.8566428571428572\n","Epoch 1/10\n","394/394 [==============================] - 3s 5ms/step - loss: 0.5124 - mask_loss: 0.4607 - feature_loss: 0.0259\n","Epoch 2/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4800 - mask_loss: 0.4554 - feature_loss: 0.0123\n","Epoch 3/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4744 - mask_loss: 0.4543 - feature_loss: 0.0101\n","Epoch 4/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4712 - mask_loss: 0.4533 - feature_loss: 0.0089\n","Epoch 5/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4689 - mask_loss: 0.4523 - feature_loss: 0.0083\n","Epoch 6/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4668 - mask_loss: 0.4510 - feature_loss: 0.0079\n","Epoch 7/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4647 - mask_loss: 0.4492 - feature_loss: 0.0078\n","Epoch 8/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4623 - mask_loss: 0.4469 - feature_loss: 0.0077\n","Epoch 9/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4593 - mask_loss: 0.4439 - feature_loss: 0.0077\n","Epoch 10/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4558 - mask_loss: 0.4404 - feature_loss: 0.0077\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 38.\n","Epoch 88: early stopping\n","HEXR-Self Performance: 0.8541428571428571\n","Epoch 1/10\n","394/394 [==============================] - 3s 5ms/step - loss: 0.5331 - mask_loss: 0.4660 - feature_loss: 0.0335\n","Epoch 2/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4960 - mask_loss: 0.4556 - feature_loss: 0.0202\n","Epoch 3/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4830 - mask_loss: 0.4491 - feature_loss: 0.0170\n","Epoch 4/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4726 - mask_loss: 0.4417 - feature_loss: 0.0154\n","Epoch 5/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4630 - mask_loss: 0.4340 - feature_loss: 0.0145\n","Epoch 6/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4544 - mask_loss: 0.4265 - feature_loss: 0.0139\n","Epoch 7/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4472 - mask_loss: 0.4202 - feature_loss: 0.0135\n","Epoch 8/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4414 - mask_loss: 0.4149 - feature_loss: 0.0133\n","Epoch 9/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4366 - mask_loss: 0.4105 - feature_loss: 0.0130\n","Epoch 10/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4326 - mask_loss: 0.4069 - feature_loss: 0.0128\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 5.\n","Epoch 55: early stopping\n","VIME-Self Performance: 0.8480714285714286\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 10.\n","Epoch 60: early stopping\n","VIME MLP performance : 0.8475\n","Epoch 1/10\n","394/394 [==============================] - 3s 5ms/step - loss: 0.4970 - mask_loss: 0.4594 - feature_loss: 0.0188\n","Epoch 2/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4765 - mask_loss: 0.4548 - feature_loss: 0.0109\n","Epoch 3/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4722 - mask_loss: 0.4536 - feature_loss: 0.0093\n","Epoch 4/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4697 - mask_loss: 0.4525 - feature_loss: 0.0086\n","Epoch 5/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4676 - mask_loss: 0.4511 - feature_loss: 0.0082\n","Epoch 6/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4654 - mask_loss: 0.4494 - feature_loss: 0.0080\n","Epoch 7/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4629 - mask_loss: 0.4471 - feature_loss: 0.0079\n","Epoch 8/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4601 - mask_loss: 0.4443 - feature_loss: 0.0079\n","Epoch 9/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4569 - mask_loss: 0.4410 - feature_loss: 0.0079\n","Epoch 10/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4534 - mask_loss: 0.4375 - feature_loss: 0.0080\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 26.\n","Epoch 76: early stopping\n","HEXR-Self Performance: 0.8542857142857143\n","Epoch 1/10\n","394/394 [==============================] - 3s 5ms/step - loss: 0.5334 - mask_loss: 0.4661 - feature_loss: 0.0337\n","Epoch 2/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4963 - mask_loss: 0.4558 - feature_loss: 0.0203\n","Epoch 3/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4834 - mask_loss: 0.4493 - feature_loss: 0.0170\n","Epoch 4/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4729 - mask_loss: 0.4420 - feature_loss: 0.0155\n","Epoch 5/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4633 - mask_loss: 0.4341 - feature_loss: 0.0146\n","Epoch 6/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4547 - mask_loss: 0.4267 - feature_loss: 0.0140\n","Epoch 7/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4476 - mask_loss: 0.4205 - feature_loss: 0.0136\n","Epoch 8/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4418 - mask_loss: 0.4153 - feature_loss: 0.0133\n","Epoch 9/10\n","394/394 [==============================] - 2s 6ms/step - loss: 0.4371 - mask_loss: 0.4110 - feature_loss: 0.0130\n","Epoch 10/10\n","394/394 [==============================] - 3s 9ms/step - loss: 0.4332 - mask_loss: 0.4074 - feature_loss: 0.0129\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 12.\n","Epoch 62: early stopping\n","VIME-Self Performance: 0.8483571428571428\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 10.\n","Epoch 60: early stopping\n","VIME MLP performance : 0.8462857142857143\n","Epoch 1/10\n","394/394 [==============================] - 3s 5ms/step - loss: 0.5055 - mask_loss: 0.4600 - feature_loss: 0.0228\n","Epoch 2/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4784 - mask_loss: 0.4550 - feature_loss: 0.0117\n","Epoch 3/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4733 - mask_loss: 0.4539 - feature_loss: 0.0097\n","Epoch 4/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4704 - mask_loss: 0.4529 - feature_loss: 0.0088\n","Epoch 5/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4683 - mask_loss: 0.4518 - feature_loss: 0.0083\n","Epoch 6/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4662 - mask_loss: 0.4503 - feature_loss: 0.0080\n","Epoch 7/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4641 - mask_loss: 0.4484 - feature_loss: 0.0078\n","Epoch 8/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4615 - mask_loss: 0.4459 - feature_loss: 0.0078\n","Epoch 9/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4585 - mask_loss: 0.4430 - feature_loss: 0.0078\n","Epoch 10/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4551 - mask_loss: 0.4395 - feature_loss: 0.0078\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","Restoring model weights from the end of the best epoch: 19.\n","Epoch 69: early stopping\n","HEXR-Self Performance: 0.8479285714285715\n","Epoch 1/10\n","394/394 [==============================] - 3s 5ms/step - loss: 0.5336 - mask_loss: 0.4661 - feature_loss: 0.0338\n","Epoch 2/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4966 - mask_loss: 0.4560 - feature_loss: 0.0203\n","Epoch 3/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4837 - mask_loss: 0.4497 - feature_loss: 0.0170\n","Epoch 4/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4734 - mask_loss: 0.4424 - feature_loss: 0.0155\n","Epoch 5/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4638 - mask_loss: 0.4347 - feature_loss: 0.0146\n","Epoch 6/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4553 - mask_loss: 0.4273 - feature_loss: 0.0140\n","Epoch 7/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4481 - mask_loss: 0.4210 - feature_loss: 0.0136\n","Epoch 8/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4422 - mask_loss: 0.4157 - feature_loss: 0.0133\n","Epoch 9/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4374 - mask_loss: 0.4113 - feature_loss: 0.0131\n","Epoch 10/10\n","394/394 [==============================] - 2s 5ms/step - loss: 0.4335 - mask_loss: 0.4077 - feature_loss: 0.0129\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","Restoring model weights from the end of the best epoch: 11.\n","Epoch 61: early stopping\n","VIME-Self Performance: 0.8575\n"]}]},{"cell_type":"code","source":["results_HEXR_acc, results_HEXR_auc, results_VIME_acc, results_VIME_auc, hexrSup_test_acc , hexrSup_test_auc, vimeSup_test_acc, vimeSup_test_auc"],"metadata":{"id":"URjImq-2gYO-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661508455733,"user_tz":-330,"elapsed":864,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"c216258a-5e7d-4d2c-b7fa-fd41dd0f772e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.8582142857142857,\n","  0.8527142857142858,\n","  0.8541428571428571,\n","  0.8542857142857143,\n","  0.8479285714285715],\n"," [0.998130498030959,\n","  0.9975044903473945,\n","  0.997027426502023,\n","  0.9975685151869312,\n","  0.9977570295275906],\n"," [0.8522142857142857,\n","  0.8517142857142858,\n","  0.8480714285714286,\n","  0.8483571428571428,\n","  0.8575],\n"," [0.9975113772490038,\n","  0.9979186966246887,\n","  0.9972286641015875,\n","  0.9980433612165304,\n","  0.9983357627170578],\n"," [],\n"," [],\n"," [0.8503571428571428,\n","  0.8490714285714286,\n","  0.8566428571428572,\n","  0.8475,\n","  0.8462857142857143],\n"," [0.9973271234491704,\n","  0.9973601572314654,\n","  0.9968712455807832,\n","  0.9967986412960215,\n","  0.9955828113441277])"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["# CASE - 80:20 tests - Valence"],"metadata":{"id":"vaiCSk6ZgYce"}},{"cell_type":"code","source":["#Setting seed for rep:\n","np.random.seed(1234)\n","tf.random.set_seed(1234)"],"metadata":{"id":"m2gcsCrLgYcf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd \n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","import supervised_models\n","import vime_self\n","import hexr_self\n","import utils\n","from supervised_models import logit, mlp\n","from utils import mask_generator, pretext_generator\n","from hexr_self import hexr_self\n","from vime_self import vime_self\n","from utils import perf_metric\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend\n","\n","#to load VIME original\n","\n","# from supervised_models import logit, mlp\n","# from vime_utils import mask_generator, pretext_generator\n","# from vime_self import vime_self\n","# from vime_utils import perf_metric"],"metadata":{"id":"n3RKVGkIgYcf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["valence"],"metadata":{"id":"Rxgm_GsigYcg"}},{"cell_type":"code","source":["#Run this cell for CASE\n","\n","df = pd.read_csv('/content/drive/MyDrive/HEXR/Data/CASE_2class.csv')\n","\n","ohe = OneHotEncoder()\n","#Choose either class1 or class2 to select either valence or arousal\n","df_ohe = pd.DataFrame(ohe.fit_transform(df[['class1']]).toarray())\n","df = df.join(df_ohe)\n","\n","df.drop('class1', axis=1, inplace=True)\n","df.drop('class2', axis=1, inplace=True)\n","df.drop('Unnamed: 0', axis=1, inplace=True)\n","df.drop('valence', axis=1, inplace=True)\n","df.drop('arousal', axis=1, inplace=True)\n","X = df.loc[:,:'emg_trap']\n","y = df.iloc[:,8:]\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","\"\"\"\n","Split used in accordance with VIME @ Neurips 2020 for comparison:\n","20% :- Test \n","10% of 80% = 8% :- Labelled dataset\n","90% of 80% = 72% :- Unlabelled dataset\n","\"\"\"\n","X_L, X_U, y_L, y_test = train_test_split(X,y,test_size=0.20,random_state=7) \n","\n","#converting to numpy arrays\n","X_L = X_L.iloc[:, :].values\n","y_L = y_L.iloc[:, :].values\n","X_U = X_U.iloc[:,:].values\n","y_test = y_test.iloc[:,:].values\n","X_L.shape, X_U.shape, y_L.shape, y_test.shape\n","\n","\n","x_train = X_L\n","y_train = y_L\n","x_test = X_U\n","y_test = y_test"],"metadata":{"id":"uH2jvGlggYcg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_L.shape, X_U.shape, y_L.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661494814688,"user_tz":-330,"elapsed":1006,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"ce56e717-390a-43f5-ef33-7a7febb7492e","id":"kwepqrTagYcg"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1176768, 8), (294192, 8), (1176768, 2), (294192, 2))"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Experimental parameters\n","label_no = 1000  \n","model_sets = ['logit','mlp']\n","\n","#reconstuction loss is log cosh\n","#recon_loss = log_cosh\n","\n","# Hyper-parameters\n","p_m = 0.3\n","alpha = 2.0\n","K = 3\n","beta = 1.0\n","label_data_rate = 0.1\n","\n","# Metric\n","metric1 = 'acc'\n","metric2 = 'auc'"],"metadata":{"id":"_4z4lb5GgYcg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Divide labeled and unlabeled data\n","idx = np.random.permutation(len(y_train))\n","\n","# Label data : Unlabeled data = label_data_rate:(1-label_data_rate)\n","label_idx = idx[:int(len(idx)*label_data_rate)]\n","unlab_idx = idx[int(len(idx)*label_data_rate):]\n","\n","# Unlabeled data\n","x_unlab = x_train[unlab_idx, :]\n","\n","# Labeled data\n","x_train = x_train[label_idx, :] \n","y_train = y_train[label_idx, :]"],"metadata":{"id":"hZRvnmfBgYch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape, x_unlab.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661494825692,"user_tz":-330,"elapsed":7,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"e0711570-c345-4aeb-ac2d-712fe8e1c573","id":"Ip5NxXlxgYch"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((117676, 8), (1059092, 8))"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["len(x_train[0, :])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661338826518,"user_tz":-330,"elapsed":3,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"8de763c7-4f26-4a93-85bb-12e9ff19769c","id":"Z8oij1FugYch"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["\"\"\" \n","Scaling for Original VIME\n","\"\"\"\n","\n","\"\"\"Min-Max scaling only for original VIME\"\"\"\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","\n","X[['ecg', 'bvp', 'gsr', 'rsp', 'skt', 'emg_zygo', 'emg_coru', 'emg_trap']] = scaler.fit_transform(X[['ecg', 'bvp', 'gsr', 'rsp', 'skt', 'emg_zygo', 'emg_coru', 'emg_trap']])\n","\n","from sklearn.model_selection import train_test_split\n","\n","\"\"\"\n","Split used in accordance with VIME @ Neurips 2020 for comparison:\n","20% :- Test \n","10% of 80% = 8% :- Labelled dataset\n","90% of 80% = 72% :- Unlabelled dataset\n","\"\"\"\n","X_L_vime, X_U_vime, y_L_vime, y_test_vime = train_test_split(X,y,test_size=0.20,random_state=7) \n","\n","#converting to numpy arrays\n","X_L_vime = X_L_vime.iloc[:, :].values\n","y_L_vime = y_L_vime.iloc[:, :].values\n","X_U_vime = X_U_vime.iloc[:,:].values\n","y_test_vime = y_test_vime.iloc[:,:].values\n","\n","x_train_vime = X_L_vime\n","y_train_vime = y_L_vime\n","x_test_vime = X_U_vime\n","y_test_vime = y_test_vime\n","\n","# Unlabeled data\n","x_unlab_vime = x_train_vime[unlab_idx, :]\n","\n","# Labeled data\n","x_train_vime = x_train_vime[label_idx, :] \n","y_train_vime = y_train_vime[label_idx, :]"],"metadata":{"id":"zbO4z4YzgYch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlp_parameters = dict()\n","mlp_parameters['hidden_dim'] = 100\n","mlp_parameters['epochs'] = 100\n","mlp_parameters['activation'] = 'relu'\n","mlp_parameters['batch_size'] = 128\n","mlp_parameters['num_layers'] = 5"],"metadata":{"id":"H5NTowsRgYch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","MLP suggested by HEXR\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import backend\n","\n","from tensorflow.keras.layers import LeakyReLU\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","import math\n","\n","\"\"\"\n","Parameterized Activation functions.\n","\"\"\"\n","\n","\"\"\"\n","Initializing parameters. We observe that a initialization from Uniform distribution \n","yield a better result than normal distribution.\n","\"\"\"\n","\n","initializer0 = keras.initializers.RandomUniform(minval = -1, maxval =1)\n","initializer1 = keras.initializers.RandomUniform(minval = 0.5, maxval =3) \n","\n","def param_elliot_function( signal, k1, k2 ,  derivative=False ):\n","    \"\"\" A parameterized version of Elliot activation function \"\"\"\n","    s = 1 # steepness\n","    \n","    abs_signal = (1 + tf.math.abs(signal * s))\n","    if derivative:\n","        return 0.5 * s / abs_signal**2\n","    else:\n","        # Return the activation signal\n","        return (k1*(signal * s) / abs_signal + k2)\n","\n","class ParamElliotfn(keras.layers.Layer):\n","    def __init__(self, trainable = True):\n","        super(ParamElliotfn, self).__init__()\n","        self.k1 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","        self.k2 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)\n","    def call(self, inputs):\n","        return param_elliot_function(inputs, self.k1, self.k2 )\n","\n","\n","def hexr_mlp(x_train, y_train, x_test, parameters):\n","\n","  print(\"HEXR MLP\")\n","\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  # K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  # Arelu = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","  \n","  print(\"Supervised MLP training sing Parameterized Elliot activation.\") \n","  Elliot = ParamElliotfn()\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = Elliot))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = Elliot))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # print(\"Balancing classes\") \n","  # from sklearn.utils.class_weight import compute_sample_weight\n","  # sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n","\n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid),epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","\n","  \n","  return y_test_hat"],"metadata":{"id":"xYjrxAV-gYch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain (VIME) Codebase.\n","\n","Reference: Jinsung Yoon, Yao Zhang, James Jordon, Mihaela van der Schaar, \n","\"VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain,\" \n","Neural Information Processing Systems (NeurIPS), 2020.\n","Paper link: TBD\n","Last updated Date: October 11th 2020\n","Code author: Jinsung Yoon (jsyoon0823@gmail.com)\n","-----------------------------\n","\n","supervised_models.py\n","- Train supervised model and return predictions on the testing data\n","\n","(1) logit: logistic regression\n","(2) xgb_model: XGBoost model\n","(3) mlp: multi-layer perceptrons\n","\"\"\"\n","\n","# Necessary packages\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","import xgboost as xgb\n","\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping\n","\n","from utils import convert_matrix_to_vector, convert_vector_to_matrix\n","\n","  \n","#%% \n","def vime_mlp(x_train, y_train, x_test, parameters):\n","  print(\"VIME MLP\")\n","  \"\"\"Multi-layer perceptron (MLP).\n","  \n","  Args: \n","    - x_train, y_train: training dataset\n","    - x_test: testing feature\n","    - parameters: hidden_dim, epochs, activation, batch_size\n","    \n","  Returns:\n","    - y_test_hat: predicted values for x_test\n","  \"\"\"  \n","  \n","  # Convert labels into proper format\n","  if len(y_train.shape) == 1:\n","    y_train = convert_vector_to_matrix(y_train)\n","    \n","  # Divide training and validation sets (9:1)\n","  idx = np.random.permutation(len(x_train[:, 0]))\n","  train_idx = idx[:int(len(idx)*0.9)]\n","  valid_idx = idx[int(len(idx)*0.9):]\n","  \n","  # Validation set\n","  x_valid = x_train[valid_idx, :]\n","  y_valid = y_train[valid_idx, :]\n","  \n","  # Training set\n","  x_train = x_train[train_idx, :]\n","  y_train = y_train[train_idx, :]  \n","  \n","  # Reset the graph\n","  K.clear_session()\n","    \n","  # Define network parameters\n","  hidden_dim = parameters['hidden_dim']\n","  epochs_size = parameters['epochs']\n","  act_fn = parameters['activation']\n","  batch_size = parameters['batch_size']\n","  \n","  # Define basic parameters\n","  data_dim = len(x_train[0, :])\n","  label_dim = len(y_train[0, :])\n","\n","  # Build model\n","  model = Sequential()\n","  model.add(Dense(hidden_dim, input_dim = data_dim, activation = act_fn))\n","  for i in range(0,parameters['num_layers']-1):\n","    model.add(Dense(hidden_dim, activation = act_fn))  \n","  model.add(Dense(label_dim, activation = 'softmax'))\n","  \n","  model.compile(loss = 'categorical_crossentropy', optimizer='adam', \n","                metrics = ['acc'])\n","  \n","  es = EarlyStopping(monitor='val_loss', mode = 'min', \n","                     verbose = 1, restore_best_weights=True, patience=50)\n","  \n","  # Fit model on training dataset\n","  model.fit(x_train, y_train, validation_data = (x_valid, y_valid), \n","            epochs = epochs_size, batch_size = batch_size, \n","            verbose = 0, callbacks=[es])\n","  \n","  # Predict on x_test\n","  y_test_hat = model.predict(x_test)\n","  \n","  return y_test_hat"],"metadata":{"id":"8XjdAqXqgYci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_HEXR_acc = []\n","results_HEXR_auc = []\n","results_VIME_acc = []\n","results_VIME_auc = []\n","hexrSup_test_acc = []\n","hexrSup_test_auc = []\n","vimeSup_test_acc = []\n","vimeSup_test_auc = []\n","\n","\n","for i in range(0,5):\n","\n","  mlp_parameters = dict()\n","  mlp_parameters['hidden_dim'] = 100\n","  mlp_parameters['epochs'] = 100\n","  mlp_parameters['activation'] = 'relu'\n","  mlp_parameters['batch_size'] = 128\n","  mlp_parameters['num_layers'] = 5\n","  \n","  #supervised - HEXR\n","  # y_test_hat = hexr_mlp(x_train, y_train, x_test, mlp_parameters)\n","  # mlp_perf1 = perf_metric(metric1, y_test, y_test_hat)\n","  # hexrSup_test_acc.append(mlp_perf1)\n","  # hexrSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  # print(\"HEXR MLP performance : {}\".format(mlp_perf1))\n","\n","  #supervised - VIME\n","  y_test_hat = vime_mlp(x_train, y_train, x_test, mlp_parameters)\n","  mlp_perf2 = perf_metric(metric1, y_test, y_test_hat)\n","  vimeSup_test_acc.append(mlp_perf2)\n","  vimeSup_test_auc.append(perf_metric(metric2, y_test, y_test_hat))\n","  print(\"VIME MLP performance : {}\".format(mlp_perf2))\n","\n","  # Train HEXR-Self \n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  hexr_self_encoder = hexr_self(x_unlab, p_m, alpha, vime_self_parameters)\n","    \n","  # Save encoder\n","  if not os.path.exists('save_model'):\n","    os.makedirs('save_model')\n","\n","  file_name = './save_model/HEXR_encoder_model_arousal_{}.h5'.format(i)\n","    \n","  hexr_self_encoder.save(file_name)  \n","          \n","  # Test HEXR-Self\n","  x_train_hat = hexr_self_encoder.predict(x_train)\n","  x_test_hat = hexr_self_encoder.predict(x_test)\n","        \n","  y_test_hat1 = vime_mlp(x_train_hat, y_train, x_test_hat, mlp_parameters)\n","  res = perf_metric(metric1, y_test, y_test_hat1)\n","  results_HEXR_acc.append(perf_metric(metric1, y_test, y_test_hat1))\n","  results_HEXR_auc.append(perf_metric(metric2, y_test, y_test_hat1))\n","        \n","  print('HEXR-Self Performance: ' + str(res))\n","\n","  #Train VIME self\n","  vime_self_parameters = dict()\n","  vime_self_parameters['batch_size'] = 128\n","  vime_self_parameters['epochs'] = 10\n","  vime_self_encoder = vime_self(x_unlab_vime, p_m, alpha, vime_self_parameters)\n","\n","  file_name = './save_model/VIME_encoder_model_arousal_{}.h5'.format(i)\n","    \n","  vime_self_encoder.save(file_name)  \n","          \n","  # Test VIME-Self\n","  x_train_hat = vime_self_encoder.predict(x_train_vime)\n","  x_test_hat = vime_self_encoder.predict(x_test_vime)\n","        \n","  y_test_hat2 = vime_mlp(x_train_hat, y_train_vime, x_test_hat, mlp_parameters)\n","  res2 = perf_metric(metric1, y_test_vime, y_test_hat2)\n","  results_VIME_acc.append(res2)\n","  results_VIME_auc.append(perf_metric(metric2, y_test_vime, y_test_hat2))\n","        \n","  print('VIME-Self Performance: ' + str(res2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661502122724,"user_tz":-330,"elapsed":7266517,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"outputId":"16cebee9-36d5-4f07-a6ae-4c6da2ccd6d5","id":"j7ZmdDKQgYci"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME MLP performance : 0.8656183716756404\n","Epoch 1/10\n","8275/8275 [==============================] - 34s 4ms/step - loss: 8.8880 - mask_loss: 0.6140 - feature_loss: 4.1370\n","Epoch 2/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 5.1846 - mask_loss: 0.6126 - feature_loss: 2.2860\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.8108 - mask_loss: 0.6119 - feature_loss: 2.0995\n","Epoch 4/10\n","8275/8275 [==============================] - 35s 4ms/step - loss: 4.6307 - mask_loss: 0.6112 - feature_loss: 2.0098\n","Epoch 5/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.5724 - mask_loss: 0.6109 - feature_loss: 1.9807\n","Epoch 6/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.5288 - mask_loss: 0.6107 - feature_loss: 1.9591\n","Epoch 7/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4882 - mask_loss: 0.6107 - feature_loss: 1.9388\n","Epoch 8/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4534 - mask_loss: 0.6107 - feature_loss: 1.9213\n","Epoch 9/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4241 - mask_loss: 0.6107 - feature_loss: 1.9067\n","Epoch 10/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4001 - mask_loss: 0.6107 - feature_loss: 1.8947\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8761489095556644\n","Epoch 1/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6337 - mask_loss: 0.6123 - feature_loss: 0.0107\n","Epoch 2/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6253 - mask_loss: 0.6095 - feature_loss: 0.0079\n","Epoch 3/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6249 - mask_loss: 0.6092 - feature_loss: 0.0079\n","Epoch 4/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 0.6246 - mask_loss: 0.6089 - feature_loss: 0.0078\n","Epoch 5/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6243 - mask_loss: 0.6088 - feature_loss: 0.0078\n","Epoch 6/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6242 - mask_loss: 0.6087 - feature_loss: 0.0078\n","Epoch 7/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6242 - mask_loss: 0.6087 - feature_loss: 0.0078\n","Epoch 8/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6242 - mask_loss: 0.6087 - feature_loss: 0.0078\n","Epoch 9/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6242 - mask_loss: 0.6086 - feature_loss: 0.0078\n","Epoch 10/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6241 - mask_loss: 0.6086 - feature_loss: 0.0078\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8539117311143742\n","VIME MLP\n","VIME MLP performance : 0.8692690487844673\n","Epoch 1/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 8.5601 - mask_loss: 0.6153 - feature_loss: 3.9724\n","Epoch 2/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 5.3467 - mask_loss: 0.6124 - feature_loss: 2.3671\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.8263 - mask_loss: 0.6116 - feature_loss: 2.1074\n","Epoch 4/10\n","8275/8275 [==============================] - 35s 4ms/step - loss: 4.5939 - mask_loss: 0.6115 - feature_loss: 1.9912\n","Epoch 5/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4952 - mask_loss: 0.6114 - feature_loss: 1.9419\n","Epoch 6/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4098 - mask_loss: 0.6114 - feature_loss: 1.8992\n","Epoch 7/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.3503 - mask_loss: 0.6114 - feature_loss: 1.8694\n","Epoch 8/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.3183 - mask_loss: 0.6114 - feature_loss: 1.8534\n","Epoch 9/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.2979 - mask_loss: 0.6115 - feature_loss: 1.8432\n","Epoch 10/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.2816 - mask_loss: 0.6114 - feature_loss: 1.8351\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8797757926796106\n","Epoch 1/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6324 - mask_loss: 0.6126 - feature_loss: 0.0099\n","Epoch 2/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6268 - mask_loss: 0.6109 - feature_loss: 0.0079\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 0.6257 - mask_loss: 0.6099 - feature_loss: 0.0079\n","Epoch 4/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6247 - mask_loss: 0.6089 - feature_loss: 0.0079\n","Epoch 5/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6244 - mask_loss: 0.6087 - feature_loss: 0.0079\n","Epoch 6/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6243 - mask_loss: 0.6086 - feature_loss: 0.0079\n","Epoch 7/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6243 - mask_loss: 0.6086 - feature_loss: 0.0078\n","Epoch 8/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6242 - mask_loss: 0.6085 - feature_loss: 0.0078\n","Epoch 9/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6241 - mask_loss: 0.6085 - feature_loss: 0.0078\n","Epoch 10/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 0.6237 - mask_loss: 0.6081 - feature_loss: 0.0078\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8287342959699788\n","VIME MLP\n","VIME MLP performance : 0.8633749388154675\n","Epoch 1/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 9.5059 - mask_loss: 0.6139 - feature_loss: 4.4460\n","Epoch 2/10\n","8275/8275 [==============================] - 35s 4ms/step - loss: 6.0077 - mask_loss: 0.6124 - feature_loss: 2.6977\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 5.2701 - mask_loss: 0.6114 - feature_loss: 2.3293\n","Epoch 4/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 5.0430 - mask_loss: 0.6109 - feature_loss: 2.2161\n","Epoch 5/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.9392 - mask_loss: 0.6109 - feature_loss: 2.1641\n","Epoch 6/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.6332 - mask_loss: 0.6113 - feature_loss: 2.0109\n","Epoch 7/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4003 - mask_loss: 0.6113 - feature_loss: 1.8945\n","Epoch 8/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.3402 - mask_loss: 0.6113 - feature_loss: 1.8644\n","Epoch 9/10\n","8275/8275 [==============================] - 34s 4ms/step - loss: 4.3130 - mask_loss: 0.6113 - feature_loss: 1.8509\n","Epoch 10/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.2992 - mask_loss: 0.6112 - feature_loss: 1.8440\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8890112579539893\n","Epoch 1/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6324 - mask_loss: 0.6122 - feature_loss: 0.0101\n","Epoch 2/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6247 - mask_loss: 0.6090 - feature_loss: 0.0079\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 0.6240 - mask_loss: 0.6084 - feature_loss: 0.0078\n","Epoch 4/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6232 - mask_loss: 0.6078 - feature_loss: 0.0077\n","Epoch 5/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6227 - mask_loss: 0.6073 - feature_loss: 0.0077\n","Epoch 6/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6225 - mask_loss: 0.6071 - feature_loss: 0.0077\n","Epoch 7/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6224 - mask_loss: 0.6070 - feature_loss: 0.0077\n","Epoch 8/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6223 - mask_loss: 0.6068 - feature_loss: 0.0077\n","Epoch 9/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6221 - mask_loss: 0.6067 - feature_loss: 0.0077\n","Epoch 10/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6220 - mask_loss: 0.6065 - feature_loss: 0.0077\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8647821830641214\n","VIME MLP\n","VIME MLP performance : 0.8661826290313809\n","Epoch 1/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 8.1950 - mask_loss: 0.6136 - feature_loss: 3.7907\n","Epoch 2/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 5.1939 - mask_loss: 0.6119 - feature_loss: 2.2910\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.7967 - mask_loss: 0.6121 - feature_loss: 2.0923\n","Epoch 4/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.6195 - mask_loss: 0.6114 - feature_loss: 2.0041\n","Epoch 5/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4992 - mask_loss: 0.6115 - feature_loss: 1.9439\n","Epoch 6/10\n","8275/8275 [==============================] - 35s 4ms/step - loss: 4.4059 - mask_loss: 0.6113 - feature_loss: 1.8973\n","Epoch 7/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.3530 - mask_loss: 0.6112 - feature_loss: 1.8709\n","Epoch 8/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.3282 - mask_loss: 0.6112 - feature_loss: 1.8585\n","Epoch 9/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.3141 - mask_loss: 0.6112 - feature_loss: 1.8514\n","Epoch 10/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 4.3057 - mask_loss: 0.6112 - feature_loss: 1.8473\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8823965301571762\n","Epoch 1/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6355 - mask_loss: 0.6122 - feature_loss: 0.0116\n","Epoch 2/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6252 - mask_loss: 0.6093 - feature_loss: 0.0079\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 0.6239 - mask_loss: 0.6082 - feature_loss: 0.0078\n","Epoch 4/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6235 - mask_loss: 0.6078 - feature_loss: 0.0078\n","Epoch 5/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6233 - mask_loss: 0.6076 - feature_loss: 0.0078\n","Epoch 6/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6232 - mask_loss: 0.6075 - feature_loss: 0.0078\n","Epoch 7/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6232 - mask_loss: 0.6075 - feature_loss: 0.0078\n","Epoch 8/10\n","8275/8275 [==============================] - 29s 4ms/step - loss: 0.6231 - mask_loss: 0.6074 - feature_loss: 0.0078\n","Epoch 9/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6231 - mask_loss: 0.6074 - feature_loss: 0.0078\n","Epoch 10/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 0.6231 - mask_loss: 0.6074 - feature_loss: 0.0078\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8367800620003263\n","VIME MLP\n","VIME MLP performance : 0.8717640180562354\n","Epoch 1/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 8.7148 - mask_loss: 0.6139 - feature_loss: 4.0504\n","Epoch 2/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 5.3414 - mask_loss: 0.6125 - feature_loss: 2.3644\n","Epoch 3/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.9253 - mask_loss: 0.6117 - feature_loss: 2.1568\n","Epoch 4/10\n","8275/8275 [==============================] - 36s 4ms/step - loss: 4.6601 - mask_loss: 0.6114 - feature_loss: 2.0244\n","Epoch 5/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.5439 - mask_loss: 0.6113 - feature_loss: 1.9663\n","Epoch 6/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.4849 - mask_loss: 0.6113 - feature_loss: 1.9368\n","Epoch 7/10\n","8275/8275 [==============================] - 32s 4ms/step - loss: 4.4450 - mask_loss: 0.6114 - feature_loss: 1.9168\n","Epoch 8/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.4049 - mask_loss: 0.6115 - feature_loss: 1.8967\n","Epoch 9/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.3704 - mask_loss: 0.6114 - feature_loss: 1.8795\n","Epoch 10/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 4.3459 - mask_loss: 0.6113 - feature_loss: 1.8673\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Proposed self supervised learning framework (param act function + log cosh loss)\n","VIME MLP\n","HEXR-Self Performance: 0.8664409637243705\n","Epoch 1/10\n","8275/8275 [==============================] - 31s 4ms/step - loss: 0.6318 - mask_loss: 0.6117 - feature_loss: 0.0100\n","Epoch 2/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6251 - mask_loss: 0.6093 - feature_loss: 0.0079\n","Epoch 3/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6235 - mask_loss: 0.6078 - feature_loss: 0.0079\n","Epoch 4/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6228 - mask_loss: 0.6072 - feature_loss: 0.0078\n","Epoch 5/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6224 - mask_loss: 0.6068 - feature_loss: 0.0078\n","Epoch 6/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6219 - mask_loss: 0.6063 - feature_loss: 0.0078\n","Epoch 7/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6216 - mask_loss: 0.6059 - feature_loss: 0.0078\n","Epoch 8/10\n","8275/8275 [==============================] - 33s 4ms/step - loss: 0.6212 - mask_loss: 0.6056 - feature_loss: 0.0078\n","Epoch 9/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6210 - mask_loss: 0.6054 - feature_loss: 0.0078\n","Epoch 10/10\n","8275/8275 [==============================] - 30s 4ms/step - loss: 0.6208 - mask_loss: 0.6052 - feature_loss: 0.0078\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["VIME MLP\n","VIME-Self Performance: 0.8491427367161581\n"]}]},{"cell_type":"code","source":["results_HEXR_acc, results_HEXR_auc, results_VIME_acc, results_VIME_auc, hexrSup_test_acc , hexrSup_test_auc, vimeSup_test_acc, vimeSup_test_auc"],"metadata":{"executionInfo":{"status":"ok","timestamp":1661507193438,"user_tz":-330,"elapsed":903,"user":{"displayName":"Hrithik Nambiar","userId":"15498796343115221793"}},"id":"I0kkesrEgYcj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"980a5d91-95d9-40e7-e718-da4e6d481395"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0.8761489095556644,\n","  0.8797757926796106,\n","  0.8890112579539893,\n","  0.8823965301571762,\n","  0.8664409637243705],\n"," [0.9399621376973174,\n","  0.9434710256580884,\n","  0.94869701315339,\n","  0.9440544910580169,\n","  0.9310075312457144],\n"," [0.8539117311143742,\n","  0.8287342959699788,\n","  0.8647821830641214,\n","  0.8367800620003263,\n","  0.8491427367161581],\n"," [0.9246817615907098,\n","  0.8922688983472837,\n","  0.931488204133242,\n","  0.9048666489288224,\n","  0.9147978833962689],\n"," [],\n"," [],\n"," [0.8656183716756404,\n","  0.8692690487844673,\n","  0.8633749388154675,\n","  0.8661826290313809,\n","  0.8717640180562354],\n"," [0.9296359393328351,\n","  0.9314211772939249,\n","  0.9263958645826601,\n","  0.9304855643790302,\n","  0.9337537594202101])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":[],"metadata":{"id":"Jjb61QSag3fT"},"execution_count":null,"outputs":[]}]}